#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®ç®¡ç†Agent - MCPå®ç°
ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„LLMæ–¹å¼ï¼Œç¡®ä¿åŠŸèƒ½å®Œå…¨ä¸€è‡´
"""

import os
import sys
import asyncio
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from mcp_agents.base.mcp_agent import MCPAgent
from mcp_agents.base.protocol import MCPMessage, MessageType
from shared.config_loader import get_config_loader

# å¯¼å…¥é¸¿è’™ç›¸å…³ç»„ä»¶
from mcp_agents.harmonyos import HarmonyOSProjectAnalyzer, HarmonyOSCompilerService

# å¯¼å…¥å·¥ä½œæµPromptç³»ç»Ÿ
from shared.workflow_prompts import WorkflowType, workflow_prompts

# å¯¼å…¥DeepSearcherç»„ä»¶ - ä¸åŸé¡¹ç›®ä¿æŒä¸€è‡´
try:
    from deepsearcher.configuration import config, init_config
    # åˆå§‹åŒ–DeepSearcheré…ç½®
    try:
        init_config(config)
        from deepsearcher.configuration import llm, embedding_model, vector_db
        logging.info("âœ… DeepSearcherç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
    except Exception as init_error:
        logging.warning(f"DeepSearcherç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {init_error}")
        llm = embedding_model = vector_db = None
except ImportError as e:
    logging.warning(f"DeepSearcheræ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    llm = embedding_model = vector_db = None

logger = logging.getLogger(__name__)

class ProjectManagerAgent(MCPAgent):
    """
    é¡¹ç›®ç®¡ç†Agent - MCPå®ç°
    ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„LLMæ–¹å¼ï¼Œç¡®ä¿åŠŸèƒ½å®Œå…¨ä¸€è‡´
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__("project_manager", config)
        
        # è·å–é…ç½®åŠ è½½å™¨
        self.config_loader = get_config_loader()
        
        # ä¼˜å…ˆä½¿ç”¨é…ç½®åŠ è½½å™¨çš„LLMï¼Œå¤‡ç”¨DeepSearcherçš„LLM
        try:
            llm_config = self.config_loader.get_llm_config("project_manager")
            logger.info(f"ğŸ” è·å–åˆ°é¡¹ç›®ç®¡ç†Agent LLMé…ç½®")
            
            if llm_config and llm_config.get("provider"):
                from shared.llm_factory import LLMFactory
                self.llm = LLMFactory.create_llm(llm_config)
                if self.llm:
                    logger.info("âœ… é¡¹ç›®ç®¡ç†Agent LLMåˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨é…ç½®åŠ è½½å™¨ï¼‰")
                else:
                    logger.warning("é…ç½®åŠ è½½å™¨è¿”å›äº†Noneï¼Œå°è¯•ä½¿ç”¨DeepSearcher LLM")
                    self.llm = llm
            else:
                logger.info("æœªæ‰¾åˆ°é¡¹ç›®ç®¡ç†Agentä¸“ç”¨é…ç½®ï¼Œä½¿ç”¨DeepSearcher LLM")
                self.llm = llm
                if self.llm:
                    logger.info("âœ… é¡¹ç›®ç®¡ç†Agent LLMåˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨DeepSearcher LLMï¼‰")
                else:
                    logger.warning("DeepSearcher LLMä¹Ÿä¸ºNone")
        except Exception as e:
            logger.error(f"é¡¹ç›®ç®¡ç†Agent LLMåˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            self.llm = llm
        
        # åˆå§‹åŒ–é¸¿è’™ç»„ä»¶
        self.harmonyos_analyzer = HarmonyOSProjectAnalyzer()
        self.harmonyos_compiler = HarmonyOSCompilerService()
        
        # é¡¹ç›®è·¯å¾„é…ç½®
        self.project_root = Path(__file__).parent.parent.parent
        self.myapplication2_path = self.project_root / "MyApplication2"
        
        # æ³¨å†ŒMCPæ–¹æ³•
        self._register_mcp_methods()
        
        # é¡¹ç›®ç®¡ç†æç¤ºè¯
        self.system_prompts = {
            "decompose": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¡¹ç›®ç®¡ç†ä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£åä¸ºæŠ€æœ¯æ ˆçš„é¡¹ç›®ç®¡ç†ã€‚
è¯·å°†ç”¨æˆ·çš„éœ€æ±‚åˆ†è§£ä¸ºå…·ä½“çš„ã€å¯æ‰§è¡Œçš„ä»»åŠ¡ã€‚æ¯ä¸ªä»»åŠ¡åº”è¯¥åŒ…å«ï¼š
1. ä»»åŠ¡æè¿°
2. ä¼˜å…ˆçº§ï¼ˆé«˜/ä¸­/ä½ï¼‰
3. é¢„ä¼°å·¥ä½œé‡ï¼ˆå°æ—¶ï¼‰
4. ä¾èµ–å…³ç³»
5. æŠ€æœ¯è¦æ±‚
6. éªŒæ”¶æ ‡å‡†

ç‰¹åˆ«å…³æ³¨åä¸ºé¸¿è’™ç³»ç»Ÿã€ArkTSã€ArkUIç­‰æŠ€æœ¯æ ˆçš„ç‰¹æ®Šè¦æ±‚ã€‚""",
            
            "validate": """ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®éœ€æ±‚éªŒè¯ä¸“å®¶ï¼Œè¯·éªŒè¯é¡¹ç›®éœ€æ±‚çš„ï¼š
1. å®Œæ•´æ€§ - éœ€æ±‚æ˜¯å¦å®Œæ•´æ¸…æ™°
2. å¯è¡Œæ€§ - æŠ€æœ¯å®ç°æ˜¯å¦å¯è¡Œ
3. åˆç†æ€§ - æ—¶é—´å’Œèµ„æºä¼°ç®—æ˜¯å¦åˆç†
4. ä¸€è‡´æ€§ - éœ€æ±‚ä¹‹é—´æ˜¯å¦å­˜åœ¨å†²çª
5. åä¸ºæŠ€æœ¯æ ˆå…¼å®¹æ€§ - æ˜¯å¦ç¬¦åˆåä¸ºå¼€å‘è§„èŒƒ

è¯·æä¾›è¯¦ç»†çš„éªŒè¯æŠ¥å‘Šå’Œæ”¹è¿›å»ºè®®ã€‚""",
            
            "estimate": """ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®å·¥ä½œé‡è¯„ä¼°ä¸“å®¶ï¼Œè¯·å¯¹é¡¹ç›®ä»»åŠ¡è¿›è¡Œå‡†ç¡®çš„å·¥ä½œé‡ä¼°ç®—ï¼š
1. å¼€å‘å·¥ä½œé‡ï¼ˆç¼–ç ã€æµ‹è¯•ã€è°ƒè¯•ï¼‰
2. è®¾è®¡å·¥ä½œé‡ï¼ˆæ¶æ„è®¾è®¡ã€UIè®¾è®¡ï¼‰
3. é›†æˆå·¥ä½œé‡ï¼ˆç³»ç»Ÿé›†æˆã€APIå¯¹æ¥ï¼‰
4. æ–‡æ¡£å·¥ä½œé‡ï¼ˆæŠ€æœ¯æ–‡æ¡£ã€ç”¨æˆ·æ‰‹å†Œï¼‰
5. é£é™©ç¼“å†²æ—¶é—´

è€ƒè™‘åä¸ºæŠ€æœ¯æ ˆçš„å­¦ä¹ æ›²çº¿å’Œç‰¹æ®Šè¦æ±‚ã€‚"""
        }
    
    def _register_mcp_methods(self):
        """æ³¨å†ŒMCPæ–¹æ³•"""
        self.methods = {
            "project.decompose": self._decompose_project,
            "project.validate": self._validate_requirements,
            "project.estimate": self._estimate_workload,
            "project.analyze": self._analyze_project,
            "project.plan": self._create_project_plan,
            "project.status": self._get_project_status,
            # æ–°å¢é¸¿è’™ä¸“ç”¨æ–¹æ³•
            "project.analyze_harmonyos": self._analyze_harmonyos_requirements,
            "project.analyze_harmonyos_requirements": self._analyze_harmonyos_requirements,
            "project.hvigor_compile": self._hvigor_compile,
            "project.check_project_health": self._check_project_health,
            "project.analyze_errors_and_generate_keywords": self._analyze_errors_and_generate_keywords
        }
    
    async def initialize(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–é¡¹ç›®ç®¡ç†Agent"""
        try:
            # å£°æ˜Agentèƒ½åŠ›
            self.declare_capability("project.decompose", {
                "description": "é¡¹ç›®éœ€æ±‚åˆ†è§£",
                "parameters": ["requirements", "context", "tech_stack"]
            })
            self.declare_capability("project.validate", {
                "description": "éœ€æ±‚éªŒè¯",
                "parameters": ["requirements", "context"]
            })
            self.declare_capability("project.estimate", {
                "description": "å·¥ä½œé‡ä¼°ç®—",
                "parameters": ["tasks", "team_size", "experience_level"]
            })
            self.declare_capability("project.analyze", {
                "description": "é¡¹ç›®åˆ†æ",
                "parameters": ["requirements", "constraints"]
            })
            self.declare_capability("project.plan", {
                "description": "é¡¹ç›®è§„åˆ’",
                "parameters": ["tasks", "timeline", "resources"]
            })
            self.declare_capability("project.analyze_errors_and_generate_keywords", {
                "description": "åˆ†æé”™è¯¯ä¿¡æ¯å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯",
                "parameters": ["errors", "original_requirement", "project_path"]
            })
            
            self.logger.info("é¡¹ç›®ç®¡ç†Agentåˆå§‹åŒ–æˆåŠŸ")
            
            return {
                "agent_id": self.agent_id,
                "capabilities": self.capabilities,
                "methods": list(self.methods.keys()),
                "llm_available": self.llm is not None,
                "status": "initialized"
            }
            
        except Exception as e:
            self.logger.error(f"é¡¹ç›®ç®¡ç†Agentåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def handle_request(self, message: MCPMessage) -> MCPMessage:
        """å¤„ç†é¡¹ç›®ç®¡ç†ç›¸å…³è¯·æ±‚"""
        try:
            method = message.method
            params = message.params or {}
            
            if method in self.methods:
                result = await self.methods[method](params)
                return self.protocol.create_response(message.id, result)
            else:
                return self.protocol.handle_method_not_found(message.id, method)
                
        except Exception as e:
            self.logger.error(f"å¤„ç†é¡¹ç›®ç®¡ç†è¯·æ±‚å¤±è´¥: {str(e)}")
            return self.protocol.handle_internal_error(message.id, str(e))
    
    async def _decompose_project(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        é¡¹ç›®éœ€æ±‚åˆ†è§£
        """
        try:
            if not self.llm:
                return {
                    "success": False,
                    "error": "LLMæœªåˆå§‹åŒ–",
                    "tasks": []
                }
            
            requirements = params.get("requirements", "")
            context = params.get("context", "")
            tech_stack = params.get("tech_stack", "åä¸ºé¸¿è’™ç³»ç»Ÿ")
            
            if not requirements:
                return {
                    "success": False,
                    "error": "é¡¹ç›®éœ€æ±‚ä¸èƒ½ä¸ºç©º",
                    "tasks": []
                }
            
            # æ„å»ºæç¤ºè¯ - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            prompt = f"""
{self.system_prompts['decompose']}

é¡¹ç›®éœ€æ±‚ï¼š
{requirements}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

æŠ€æœ¯æ ˆï¼š
{tech_stack}

è¯·å°†ä¸Šè¿°éœ€æ±‚åˆ†è§£ä¸ºå…·ä½“çš„ä»»åŠ¡æ¸…å•ï¼Œä»¥JSONæ ¼å¼è¿”å›ã€‚
"""
            
            # è°ƒç”¨LLM - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            response = self.llm.chat([{"role": "user", "content": prompt}])
            content = self.llm.remove_think(response.content) if hasattr(self.llm, 'remove_think') else response.content
            
            # è§£æLLMå“åº”
            tasks = self._parse_task_decomposition(content)
            
            return {
                "success": True,
                "requirements": requirements,
                "tech_stack": tech_stack,
                "tasks": tasks,
                "total_tasks": len(tasks),
                "llm_response": content,
                "token_usage": getattr(response, 'total_tokens', 0)
            }
            
        except Exception as e:
            logger.error(f"é¡¹ç›®éœ€æ±‚åˆ†è§£å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "tasks": []
            }
    
    async def _validate_requirements(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        éœ€æ±‚éªŒè¯
        """
        try:
            if not self.llm:
                return {
                    "success": False,
                    "error": "LLMæœªåˆå§‹åŒ–",
                    "validation_result": {}
                }
            
            requirements = params.get("requirements", "")
            context = params.get("context", "")
            
            if not requirements:
                return {
                    "success": False,
                    "error": "é¡¹ç›®éœ€æ±‚ä¸èƒ½ä¸ºç©º",
                    "validation_result": {}
                }
            
            # æ„å»ºæç¤ºè¯ - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            prompt = f"""
{self.system_prompts['validate']}

é¡¹ç›®éœ€æ±‚ï¼š
{requirements}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

è¯·å¯¹ä¸Šè¿°éœ€æ±‚è¿›è¡Œå…¨é¢éªŒè¯ï¼ŒåŒ…æ‹¬å®Œæ•´æ€§ã€å¯è¡Œæ€§ã€åˆç†æ€§ã€ä¸€è‡´æ€§å’Œåä¸ºæŠ€æœ¯æ ˆå…¼å®¹æ€§ã€‚
"""
            
            # è°ƒç”¨LLM - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            response = self.llm.chat([{"role": "user", "content": prompt}])
            content = self.llm.remove_think(response.content) if hasattr(self.llm, 'remove_think') else response.content
            
            # è§£æéªŒè¯ç»“æœ
            validation_result = self._parse_validation_result(content)
            
            return {
                "success": True,
                "requirements": requirements,
                "validation_result": validation_result,
                "llm_response": content,
                "token_usage": getattr(response, 'total_tokens', 0)
            }
            
        except Exception as e:
            logger.error(f"éœ€æ±‚éªŒè¯å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "validation_result": {}
            }
    
    async def _estimate_workload(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        å·¥ä½œé‡ä¼°ç®—
        """
        try:
            if not self.llm:
                return {
                    "success": False,
                    "error": "LLMæœªåˆå§‹åŒ–",
                    "estimation": {}
                }
            
            tasks = params.get("tasks", [])
            team_size = params.get("team_size", 3)
            experience_level = params.get("experience_level", "ä¸­çº§")
            
            if not tasks:
                return {
                    "success": False,
                    "error": "ä»»åŠ¡æ¸…å•ä¸èƒ½ä¸ºç©º",
                    "estimation": {}
                }
            
            # æ„å»ºä¼°ç®—æç¤ºè¯
            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé¡¹ç›®å·¥ä½œé‡è¯„ä¼°ä¸“å®¶ï¼Œè¯·å¯¹é¡¹ç›®ä»»åŠ¡è¿›è¡Œå‡†ç¡®çš„å·¥ä½œé‡ä¼°ç®—ï¼š

ä»»åŠ¡æ¸…å•ï¼š
{tasks}

å›¢é˜Ÿè§„æ¨¡ï¼š{team_size}äºº
ç»éªŒæ°´å¹³ï¼š{experience_level}

è¯·å¯¹ä¸Šè¿°ä»»åŠ¡è¿›è¡Œè¯¦ç»†çš„å·¥ä½œé‡ä¼°ç®—ï¼Œä»¥JSONæ ¼å¼è¿”å›ä¼°ç®—ç»“æœã€‚
"""
            
            # è°ƒç”¨LLM - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            response = self.llm.chat([{"role": "user", "content": prompt}])
            content = self.llm.remove_think(response.content) if hasattr(self.llm, 'remove_think') else response.content
            
            # è§£æä¼°ç®—ç»“æœ
            estimation = self._parse_estimation_result(content)
            
            return {
                "success": True,
                "tasks": tasks,
                "team_size": team_size,
                "experience_level": experience_level,
                "estimation": estimation,
                "llm_response": content,
                "token_usage": getattr(response, 'total_tokens', 0)
            }
            
        except Exception as e:
            logger.error(f"å·¥ä½œé‡ä¼°ç®—å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "estimation": {}
            }
    
    async def _analyze_project(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        é¡¹ç›®åˆ†æ
        """
        try:
            if not self.llm:
                return {
                    "success": False,
                    "error": "LLMæœªåˆå§‹åŒ–",
                    "analysis": {}
                }
            
            requirements = params.get("requirements", "")
            constraints = params.get("constraints", [])
            goals = params.get("goals", [])
            
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = f"""
ä½œä¸ºé¡¹ç›®åˆ†æä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹é¡¹ç›®è¿›è¡Œå…¨é¢åˆ†æï¼š

é¡¹ç›®éœ€æ±‚ï¼š
{requirements}

çº¦æŸæ¡ä»¶ï¼š
{constraints}

é¡¹ç›®ç›®æ ‡ï¼š
{goals}

è¯·ä»æŠ€æœ¯å¯è¡Œæ€§ã€èµ„æºéœ€æ±‚ã€é£é™©è¯„ä¼°ã€æ—¶é—´è§„åˆ’ç­‰è§’åº¦è¿›è¡Œåˆ†æã€‚
"""
            
            # è°ƒç”¨LLM - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            response = self.llm.chat([{"role": "user", "content": prompt}])
            content = self.llm.remove_think(response.content) if hasattr(self.llm, 'remove_think') else response.content
            
            return {
                "success": True,
                "requirements": requirements,
                "analysis": {
                    "content": content,
                    "constraints": constraints,
                    "goals": goals
                },
                "llm_response": content,
                "token_usage": getattr(response, 'total_tokens', 0)
            }
            
        except Exception as e:
            logger.error(f"é¡¹ç›®åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis": {}
            }
    
    async def _create_project_plan(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ›å»ºé¡¹ç›®è®¡åˆ’
        """
        try:
            if not self.llm:
                return {
                    "success": False,
                    "error": "LLMæœªåˆå§‹åŒ–",
                    "plan": {}
                }
            
            tasks = params.get("tasks", [])
            timeline = params.get("timeline", "4å‘¨")
            resources = params.get("resources", {})
            
            # æ„å»ºè®¡åˆ’æç¤ºè¯
            prompt = f"""
ä½œä¸ºé¡¹ç›®è®¡åˆ’ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹ä»»åŠ¡åˆ›å»ºè¯¦ç»†çš„é¡¹ç›®è®¡åˆ’ï¼š

ä»»åŠ¡æ¸…å•ï¼š
{tasks}

é¡¹ç›®æ—¶é—´çº¿ï¼š{timeline}
å¯ç”¨èµ„æºï¼š{resources}

è¯·åˆ›å»ºåŒ…å«æ—¶é—´å®‰æ’ã€èµ„æºåˆ†é…ã€é‡Œç¨‹ç¢‘çš„è¯¦ç»†é¡¹ç›®è®¡åˆ’ã€‚
"""
            
            # è°ƒç”¨LLM - ä½¿ç”¨åŸé¡¹ç›®ç›¸åŒçš„æ–¹å¼
            response = self.llm.chat([{"role": "user", "content": prompt}])
            content = self.llm.remove_think(response.content) if hasattr(self.llm, 'remove_think') else response.content
            
            return {
                "success": True,
                "tasks": tasks,
                "timeline": timeline,
                "plan": {
                    "content": content,
                    "resources": resources
                },
                "llm_response": content,
                "token_usage": getattr(response, 'total_tokens', 0)
            }
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé¡¹ç›®è®¡åˆ’å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "plan": {}
            }
    
    async def _get_project_status(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–é¡¹ç›®ç®¡ç†çŠ¶æ€"""
        try:
            return {
                "success": True,
                "status": {
                    "agent_initialized": True,
                    "llm_client_available": self.llm is not None,
                    "llm_config": self.config_loader.get_llm_config("project_manager"),
                    "capabilities": {
                        "project_decomposition": True,
                        "requirements_validation": True,
                        "workload_estimation": True,
                        "project_analysis": True,
                        "project_planning": True
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–é¡¹ç›®çŠ¶æ€å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _parse_task_decomposition(self, response: str) -> List[Dict[str, Any]]:
        """è§£æä»»åŠ¡åˆ†è§£ç»“æœ"""
        try:
            # å°è¯•è§£æJSONæ ¼å¼çš„å“åº”
            import json
            import re
            
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                tasks_json = json_match.group(0)
                tasks = json.loads(tasks_json)
                return tasks
            
            # å¦‚æœæ— æ³•è§£æJSONï¼Œè¿”å›æ–‡æœ¬è§£æç»“æœ
            return self._parse_text_to_tasks(response)
            
        except Exception as e:
            logger.error(f"è§£æä»»åŠ¡åˆ†è§£ç»“æœå¤±è´¥: {e}")
            return []
    
    def _parse_text_to_tasks(self, text: str) -> List[Dict[str, Any]]:
        """ä»æ–‡æœ¬ä¸­è§£æä»»åŠ¡"""
        tasks = []
        lines = text.split('\n')
        current_task = {}
        
        for line in lines:
            line = line.strip()
            if line.startswith('ä»»åŠ¡') or line.startswith('Task'):
                if current_task:
                    tasks.append(current_task)
                current_task = {"description": line, "priority": "ä¸­", "hours": 8}
            elif 'ä¼˜å…ˆçº§' in line or 'priority' in line.lower():
                if current_task:
                    current_task["priority"] = line.split(':')[-1].strip()
            elif 'å·¥ä½œé‡' in line or 'hours' in line.lower():
                if current_task:
                    try:
                        hours = int(re.search(r'\d+', line).group())
                        current_task["hours"] = hours
                    except:
                        current_task["hours"] = 8
        
        if current_task:
            tasks.append(current_task)
        
        return tasks
    
    def _parse_validation_result(self, response: str) -> Dict[str, Any]:
        """è§£æéªŒè¯ç»“æœ"""
        try:
            import json
            import re
            
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result_json = json_match.group(0)
                result = json.loads(result_json)
                return result
            
            # æ–‡æœ¬è§£æ
            return {
                "completeness": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
                "feasibility": "æŠ€æœ¯å¯è¡Œ",
                "reasonableness": "åŸºæœ¬åˆç†",
                "consistency": "æ— æ˜æ˜¾å†²çª",
                "huawei_compatibility": "ç¬¦åˆåä¸ºè§„èŒƒ",
                "details": response
            }
            
        except Exception as e:
            logger.error(f"è§£æéªŒè¯ç»“æœå¤±è´¥: {e}")
            return {"details": response}
    
    def _parse_estimation_result(self, response: str) -> Dict[str, Any]:
        """è§£æä¼°ç®—ç»“æœ"""
        try:
            import json
            import re
            
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result_json = json_match.group(0)
                result = json.loads(result_json)
                return result
            
            # æ–‡æœ¬è§£æ
            total_hours = 40  # é»˜è®¤å€¼
            try:
                hours_match = re.search(r'(\d+)\s*å°æ—¶', response)
                if hours_match:
                    total_hours = int(hours_match.group(1))
            except:
                pass
            
            return {
                "total_hours": total_hours,
                "development_hours": total_hours * 0.6,
                "design_hours": total_hours * 0.2,
                "integration_hours": total_hours * 0.15,
                "documentation_hours": total_hours * 0.05,
                "details": response
            }
            
        except Exception as e:
            logger.error(f"è§£æä¼°ç®—ç»“æœå¤±è´¥: {e}")
            return {"total_hours": 40, "details": response}
    
    async def get_capabilities(self) -> Dict[str, Any]:
        """è·å–Agentèƒ½åŠ›"""
        return {
            "name": "project_manager",
            "description": "åä¸ºé¡¹ç›®ç®¡ç†Agent - æ”¯æŒéœ€æ±‚åˆ†è§£ã€éªŒè¯ã€ä¼°ç®—å’Œè®¡åˆ’",
            "version": "1.0.0",
            "methods": list(self.methods.keys()),
            "resources": [
                {
                    "name": "project_tasks",
                    "description": "é¡¹ç›®ä»»åŠ¡èµ„æº",
                    "type": "application/json"
                },
                {
                    "name": "project_plan",
                    "description": "é¡¹ç›®è®¡åˆ’èµ„æº",
                    "type": "application/json"
                }
            ],
            "tools": [
                {
                    "name": "task_decomposition",
                    "description": "ä»»åŠ¡åˆ†è§£å·¥å…·"
                },
                {
                    "name": "requirement_validation",
                    "description": "éœ€æ±‚éªŒè¯å·¥å…·"
                },
                {
                    "name": "workload_estimation",
                    "description": "å·¥ä½œé‡ä¼°ç®—å·¥å…·"
                },
                {
                    "name": "project_planning",
                    "description": "é¡¹ç›®è§„åˆ’å·¥å…·"
                }
            ]
        }
    
    # ==================== é¸¿è’™ä¸“ç”¨æ–¹æ³• ====================
    
    async def _analyze_harmonyos_requirements(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æé¸¿è’™éœ€æ±‚å¹¶è§„åˆ’æ–‡ä»¶ç”Ÿæˆ - å·¥ä½œæµç¬¬ä¸€æ­¥
        
        æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œè¯¦ç»†åˆ†æå¹¶è§„åˆ’éœ€è¦ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„å’Œå†…å®¹å¤§çº²
        ä¸ºåç»­çš„æœç´¢å’Œä»£ç ç”Ÿæˆæä¾›æ˜ç¡®çš„æŒ‡å¯¼
        """
        try:
            # ä»æ–°çš„ä¸Šä¸‹æ–‡ç³»ç»Ÿè·å–å‚æ•°
            user_requirement = params.get("user_requirement", params.get("requirement", ""))
            project_path = params.get("project_path", "MyApplication2")
            task_description = params.get("task_description", "")
            current_phase = params.get("current_phase", "requirement_analysis")
            
            if not user_requirement:
                return {
                    "success": False,
                    "error": "éœ€æ±‚æè¿°ä¸èƒ½ä¸ºç©º"
                }
            
            logger.info(f"é¡¹ç›®ç®¡ç†Agentå¼€å§‹åˆ†æé¸¿è’™éœ€æ±‚")
            logger.info(f"å½“å‰é˜¶æ®µ: {current_phase}")
            logger.info(f"ä»»åŠ¡æè¿°: {task_description}")
            logger.info(f"ç”¨æˆ·éœ€æ±‚: {user_requirement}")
            
            # è¯»å–MyApplication2é¡¹ç›®ç»“æ„
            project_structure = self._read_myapplication2_structure()
            logger.info(f"æˆåŠŸè¯»å–MyApplication2é¡¹ç›®ç»“æ„ä¿¡æ¯")
            
            # è¯»å–README.mdæ–‡ä»¶ä¸­çš„è‡ªç„¶è¯­è¨€æè¿°ï¼ˆå•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼ï¼‰
            readme_content = self._read_readme_description()
            if readme_content:
                # æ— è®ºæ˜¯åˆå§‹ç”Ÿæˆè¿˜æ˜¯é”™è¯¯ä¿®å¤ï¼Œéƒ½è¦ç¡®ä¿READMEå†…å®¹å®Œæ•´ä¼ é€’
                original_user_requirement = user_requirement
                user_requirement = readme_content
                logger.info(f"ä»README.mdæ–‡ä»¶è¯»å–åˆ°è‡ªç„¶è¯­è¨€æè¿°: {len(user_requirement)} å­—ç¬¦")
                logger.info(f"åŸå§‹ç”¨æˆ·éœ€æ±‚: {original_user_requirement}")
                # åœ¨ä¸Šä¸‹æ–‡ä¸­åŒæ—¶ä¿å­˜åŸå§‹éœ€æ±‚å’ŒREADMEå†…å®¹
                self._readme_content = readme_content
                self._original_requirement = original_user_requirement
            
            # ä½¿ç”¨å·¥ä½œæµPromptç³»ç»Ÿè¿›è¡Œéœ€æ±‚åˆ†æå’Œæ–‡ä»¶è§„åˆ’

            llm_available = self.llm is not None
            logger.info(f"ğŸ¤– é¡¹ç›®ç®¡ç†Agent LLMçŠ¶æ€: {'å¯ç”¨' if llm_available else 'ä¸å¯ç”¨'}")
            logger.info(f"ğŸ” LLMå¯¹è±¡ç±»å‹: {type(self.llm)}")
            
            if llm_available:
                logger.info(f"ğŸš€ å¼€å§‹LLMåˆ†æéœ€æ±‚...")
                
                # ç¡®å®šå·¥ä½œæµç±»å‹ï¼ˆåˆå§‹ç”Ÿæˆæˆ–é”™è¯¯ä¿®å¤ï¼‰
                is_fixing = params.get('is_fixing', False)
                workflow_type = WorkflowType.ERROR_FIXING if is_fixing else WorkflowType.INITIAL_GENERATION
                
                logger.info(f"ğŸ”„ å·¥ä½œæµç±»å‹: {workflow_type.value}")
                
                # è·å–é€‚åˆçš„prompt
                system_prompt = workflow_prompts.get_prompt('project_manager', workflow_type, 'system')
                if workflow_type == WorkflowType.ERROR_FIXING:
                    current_errors = params.get('current_errors', [])
                    existing_files = params.get('existing_files', [])
                    user_prompt = workflow_prompts.format_user_prompt(
                        'project_manager', workflow_type,
                        user_requirement=user_requirement,
                        current_errors=current_errors,
                        existing_files=existing_files
                    )
                else:
                    # è·å–é¡¹ç›®æ–‡ä»¶å†…å®¹ç”¨äºæ›´å¥½çš„éœ€æ±‚åˆ†æ
                    project_context = self._get_project_context_for_llm()
                    user_prompt = workflow_prompts.format_user_prompt(
                        'project_manager', workflow_type,
                        user_requirement=user_requirement,
                        project_structure=project_structure,
                        project_context=project_context
                    )
                
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
                response = self.llm.chat(messages)
                content = self.llm.remove_think(response.content)
                logger.info(f"ğŸ“ LLMè¿”å›å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                
                # å°è¯•è§£æJSON
                import json
                try:
                    analysis_data = json.loads(content)
                    # éªŒè¯æ‰€æœ‰æ–‡ä»¶è·¯å¾„éƒ½åœ¨MyApplication2ä¸­
                    analysis_data = self._validate_and_fix_file_paths(analysis_data)
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä»æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯
                    if workflow_type == WorkflowType.ERROR_FIXING:
                        analysis_data = self._extract_error_analysis_from_text(content, params.get('current_errors', []))
                    else:
                        analysis_data = self._extract_analysis_from_text(content, user_requirement)
            else:
                # æ²¡æœ‰LLMæ—¶çš„å¤‡ç”¨åˆ†æ
                if workflow_type == WorkflowType.ERROR_FIXING:
                    analysis_data = self._extract_error_analysis_from_text("", params.get('current_errors', []))
                else:
                    analysis_data = self._generate_basic_analysis(user_requirement)
            
            # æ ¹æ®å·¥ä½œæµç±»å‹è¿”å›ä¸åŒçš„ç»“æœæ ¼å¼
            if workflow_type == WorkflowType.ERROR_FIXING:
                # é”™è¯¯ä¿®å¤é˜¶æ®µè¿”å›é”™è¯¯åˆ†æç»“æœ
                logger.info(f"é”™è¯¯åˆ†æå®Œæˆï¼Œåˆ†æäº†{len(analysis_data.get('error_analysis', []))}ä¸ªé”™è¯¯")
                
                # æ‰“å°é”™è¯¯åˆ†æè¯¦æƒ…ç”¨äºè°ƒè¯•
                for i, error_info in enumerate(analysis_data.get('error_analysis', [])):
                    logger.info(f"  é”™è¯¯{i+1}: {error_info.get('target_file', 'N/A')}")
                
                return {
                    "success": True,
                    "analysis": analysis_data,
                    "error_analysis": analysis_data.get("error_analysis", []),
                    "files_to_fix": analysis_data.get("files_to_fix", []),
                    "search_queries": analysis_data.get("search_queries", []),
                    "fix_strategies": analysis_data.get("error_analysis", []),  # ä¸ºä¸å·¥ä½œæµåè°ƒå™¨å…¼å®¹
                    "project_path": project_path
                }
            else:
                # åˆå§‹ç”Ÿæˆé˜¶æ®µè¿”å›æ–‡ä»¶è§„åˆ’ç»“æœ
                logger.info(f"éœ€æ±‚åˆ†æå®Œæˆï¼Œè§„åˆ’äº†{len(analysis_data.get('planned_files', []))}ä¸ªæ–‡ä»¶")
                
                # æ‰“å°æ–‡ä»¶è·¯å¾„è¯¦æƒ…ç”¨äºè°ƒè¯•
                for i, file_info in enumerate(analysis_data.get('planned_files', [])):
                    logger.info(f"  æ–‡ä»¶{i+1}: {file_info.get('path', 'N/A')}")
                
                return {
                    "success": True,
                    "analysis": analysis_data,
                    "planned_files": analysis_data.get("planned_files", []),
                    "search_keywords": analysis_data.get("search_keywords", []),
                    "requirement_analysis": analysis_data.get("requirement_analysis", {}),
                    "project_path": project_path
                }
                
        except Exception as e:
            logger.error(f"é¸¿è’™éœ€æ±‚åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _extract_analysis_from_text(self, content: str, user_requirement: str) -> Dict[str, Any]:
        """ä»LLMæ–‡æœ¬è¾“å‡ºä¸­æå–åˆ†æç»“æœ - å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼"""
        # å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼ï¼šåªè¿”å›Index.etsæ–‡ä»¶
        analysis_data = {
            "requirement_analysis": {
                "main_functionality": f"åŸºäºIndex.etsæ–‡ä»¶è‡ªç„¶è¯­è¨€æè¿°ç”ŸæˆArkTSé¡µé¢ç»„ä»¶",
                "key_features": ["é¡µé¢ç»„ä»¶", "UIç•Œé¢", "çŠ¶æ€ç®¡ç†"],
                "technical_requirements": ["ArkTSè¯­è¨€", "ArkUIç»„ä»¶", "@Entry @Componentè£…é¥°å™¨"]
            },
            "planned_files": [
                {
                    "path": "MyApplication2/entry/src/main/ets/pages/Index.ets",
                    "type": "page",
                    "purpose": "åº”ç”¨å…¥å£é¡µé¢ç»„ä»¶",
                    "content_outline": "@Entry @Component é¡µé¢ç»„ä»¶ï¼ŒåŒ…å«å®Œæ•´çš„UIç•Œé¢å’ŒçŠ¶æ€ç®¡ç†",
                    "key_components": ["Column", "Text", "Button", "Image"],
                    "dependencies": ["@ohos.router"]
                }
            ],
            "search_queries": [
                "HarmonyOS ArkTSé¡µé¢ç»„ä»¶å¼€å‘æ–¹æ³•å’Œ@Entry @Componentè£…é¥°å™¨ä½¿ç”¨",
                "é¸¿è’™åº”ç”¨ArkUIé¡µé¢å¸ƒå±€å’ŒçŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ",
                "ArkTSé¡µé¢ç»„ä»¶UIç»„ä»¶ä½¿ç”¨æ–¹æ³•å’Œæ ·å¼è®¾ç½®"
            ]
        }
        
        # éªŒè¯å’Œä¿®å¤æ–‡ä»¶è·¯å¾„
        return self._validate_and_fix_file_paths(analysis_data)
    
    def _generate_basic_analysis(self, user_requirement: str) -> Dict[str, Any]:
        """ç”ŸæˆåŸºç¡€åˆ†æï¼ˆæ²¡æœ‰LLMæ—¶çš„å¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        return self._extract_analysis_from_text("", user_requirement)
    
    def _extract_error_analysis_from_text(self, content: str, current_errors: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­æå–é”™è¯¯åˆ†æç»“æœï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # åŸºç¡€é”™è¯¯åˆ†æç»“æœ
        error_analysis = []
        files_to_fix = []
        search_queries = []
        
        # æ™ºèƒ½åˆ†æé”™è¯¯å¹¶æ¨æ–­æ–‡ä»¶è·¯å¾„
        for i, error in enumerate(current_errors):
            error_message = error.get("message", "")
            # æ™ºèƒ½æ¨æ–­æ–‡ä»¶è·¯å¾„
            target_file = self._infer_target_file_from_error(error_message, error.get("file_path", "unknown"))
            
            # ç”Ÿæˆç²¾ç¡®çš„æœç´¢å…³é”®è¯
            search_keywords = self._generate_specific_search_keywords(error_message)
            
            error_analysis.append({
                "error_id": i + 1,
                "error_message": error_message,
                "root_cause": self._analyze_error_root_cause(error_message),
                "target_file": target_file,
                "fix_location": self._infer_fix_location(error_message, error.get('line')),
                "fix_description": self._generate_fix_description(error_message),
                "search_keywords": search_keywords
            })
            
            # æ·»åŠ åˆ°ä¿®å¤æ–‡ä»¶åˆ—è¡¨
            if target_file != "unknown" and target_file not in [f["file_path"] for f in files_to_fix]:
                files_to_fix.append({
                    "file_path": target_file,
                    "errors": [i + 1],
                    "priority": "high"
                })
            
            # æ·»åŠ ç²¾ç¡®çš„æœç´¢å…³é”®è¯
            search_queries.extend(search_keywords)
        
        return {
            "error_analysis": error_analysis,
            "files_to_fix": files_to_fix,
            "search_queries": list(set(search_queries))  # å»é‡
        }
    
    def _infer_target_file_from_error(self, error_message: str, original_file_path: str) -> str:
        """æ ¹æ®é”™è¯¯ä¿¡æ¯æ™ºèƒ½æ¨æ–­ç›®æ ‡æ–‡ä»¶ - å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼å›ºå®šä¸ºIndex.ets"""
        # å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼ï¼šæ‰€æœ‰é”™è¯¯éƒ½æŒ‡å‘Index.etsæ–‡ä»¶
        return "MyApplication2/entry/src/main/ets/pages/Index.ets"
    
    def _analyze_error_root_cause(self, error_message: str) -> str:
        """åˆ†æé”™è¯¯æ ¹æœ¬åŸå› """
        if "Resource Pack Error" in error_message:
            return "JSONèµ„æºæ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–å†…å®¹ä¸åˆæ³•"
        elif "CompileResource" in error_message:
            return "ArkTSä»£ç ç¼–è¯‘é”™è¯¯ï¼Œå¯èƒ½æ˜¯è¯­æ³•æˆ–ç±»å‹é—®é¢˜"
        elif "Tools execution failed" in error_message:
            return "æ„å»ºå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œå¯èƒ½æ˜¯ä¾èµ–æˆ–é…ç½®é—®é¢˜"
        elif "Build failed" in error_message:
            return "æ•´ä½“æ„å»ºå¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ä»£ç è´¨é‡å’Œä¾èµ–"
        else:
            return "éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„ä»£ç é”™è¯¯"
    
    def _infer_fix_location(self, error_message: str, line_number: int) -> str:
        """æ¨æ–­ä¿®å¤ä½ç½®"""
        if line_number:
            return f"è¡Œ {line_number}"
        elif "Resource Pack Error" in error_message:
            return "JSONæ–‡ä»¶çš„æ•´ä½“ç»“æ„"
        elif "CompileResource" in error_message:
            return "ç»„ä»¶å®šä¹‰æˆ–å¯¼å…¥è¯­å¥"
        else:
            return "æ–‡ä»¶æ•´ä½“ç»“æ„"
    
    def _generate_fix_description(self, error_message: str) -> str:
        """ç”Ÿæˆä¿®å¤æè¿°"""
        if "Resource Pack Error" in error_message:
            return "æ£€æŸ¥å¹¶ä¿®å¤JSONèµ„æºæ–‡ä»¶çš„æ ¼å¼å’Œå†…å®¹"
        elif "CompileResource" in error_message:
            return "ä¿®å¤ArkTSä»£ç çš„è¯­æ³•é”™è¯¯å’Œç±»å‹é—®é¢˜"
        elif "Tools execution failed" in error_message:
            return "æ£€æŸ¥ä¸ä¿®å¤æ„å»ºå·¥å…·å’Œä¾èµ–é—®é¢˜"
        elif "Build failed" in error_message:
            return "å…¨é¢æ£€æŸ¥ä»£ç è´¨é‡å’Œé¡¹ç›®ç»“æ„"
        else:
            return f"ä¿®å¤é”™è¯¯: {error_message}"
    
    def _generate_specific_search_keywords(self, error_message: str) -> List[str]:
        """ç”Ÿæˆå…·ä½“çš„æœç´¢é—®é¢˜"""
        
        if "Resource Pack Error" in error_message:
            return [
                "HarmonyOSä¸­string.jsonæ–‡ä»¶å‡ºç°Resource Pack Errorå¦‚ä½•ä¿®å¤æ ¼å¼é”™è¯¯å’Œç»“æ„é—®é¢˜",
                "é¸¿è’™åº”ç”¨elementç›®å½•ä¸‹èµ„æºæ–‡ä»¶çš„æ­£ç¡®æ ¼å¼å’Œé…ç½®æ–¹æ³•"
            ]
        elif "CompileResource" in error_message:
            return [
                "ArkTS @Entry @Componentè£…é¥°å™¨CompileResourceé”™è¯¯çš„å¸¸è§åŸå› å’Œè§£å†³æ–¹æ³•",
                "HarmonyOS ArkTSç»„ä»¶å®šä¹‰çš„æ­£ç¡®è¯­æ³•å’Œç¼–è¯‘é”™è¯¯ä¿®å¤æŠ€å·§"
            ]
        elif "Tools execution failed" in error_message:
            return [
                "HarmonyOS hvigoræ„å»ºå‡ºç°Tools execution failedé”™è¯¯çš„æ’æŸ¥å’Œä¿®å¤æ­¥éª¤",
                "é¸¿è’™åº”ç”¨æ„å»ºå·¥å…·é…ç½®é—®é¢˜å’Œä¾èµ–ç®¡ç†çš„è§£å†³æ–¹æ¡ˆ"
            ]
        elif "Build failed" in error_message:
            return [
                "HarmonyOSé¡¹ç›®æ•´ä½“æ„å»ºå¤±è´¥Build failedçš„æ’æŸ¥æ­¥éª¤å’Œå¸¸è§è§£å†³æ–¹æ³•",
                "é¸¿è’™åº”ç”¨module.json5å’Œé¡¹ç›®ç»“æ„é…ç½®é”™è¯¯çš„ä¿®å¤æŒ‡å—"
            ]
        else:
            return [
                f"HarmonyOS ArkTSä¸­å‡ºç°ç¼–è¯‘é”™è¯¯{error_message[:50]}çš„è§£å†³æ–¹æ³•å’Œä¿®å¤æŠ€å·§",
                "é¸¿è’™åº”ç”¨å¼€å‘ä¸­å¸¸è§ä»£ç é”™è¯¯çš„è°ƒè¯•å’Œä¿®å¤æ–¹æ³•"
            ]
    
    async def _hvigor_compile(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œhvigorç¼–è¯‘æ£€æŸ¥"""
        try:
            project_path = params.get("project_path", "MyApplication2")
            
            logger.info(f"å¼€å§‹hvigorç¼–è¯‘æ£€æŸ¥: {project_path}")
            
            # ä½¿ç”¨ç¼–è¯‘æœåŠ¡æ‰§è¡Œç¼–è¯‘
            compile_result = self.harmonyos_compiler.run_hvigor_compile()
            
            # ç”Ÿæˆä¿®å¤å»ºè®®
            if not compile_result["success"] and compile_result.get("errors"):
                suggestions = self.harmonyos_compiler.generate_fix_suggestions(
                    compile_result["errors"], 
                    []
                )
                compile_result["fix_suggestions"] = suggestions
            
            logger.info(f"ç¼–è¯‘æ£€æŸ¥å®Œæˆ: {'æˆåŠŸ' if compile_result['success'] else 'å¤±è´¥'}")
            
            return {
                "success": compile_result["success"],  # åŸºäºç¼–è¯‘ç»“æœè¿”å›æ­£ç¡®çš„æˆåŠŸçŠ¶æ€
                "project_path": project_path,
                "compile_result": compile_result,
                "status": "success" if compile_result["success"] else "failed",
                "errors": compile_result.get("errors", []),
                "total_errors": compile_result.get("total_errors", 0),
                "fix_suggestions": compile_result.get("fix_suggestions", [])
            }
            
        except Exception as e:
            logger.error(f"hvigorç¼–è¯‘å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "status": "failed",
                "compile_result": {}
            }
    
    async def _check_project_health(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥é¡¹ç›®å¥åº·çŠ¶å†µ"""
        try:
            logger.info("å¼€å§‹æ£€æŸ¥é¡¹ç›®å¥åº·çŠ¶å†µ")
            
            # ä½¿ç”¨ç¼–è¯‘æœåŠ¡æ£€æŸ¥é¡¹ç›®å¥åº·çŠ¶å†µ
            health_result = self.harmonyos_compiler.check_project_health()
            
            # è·å–é¡¹ç›®ç»“æ„ä¿¡æ¯
            project_info = self.harmonyos_analyzer.get_project_info()
            
            logger.info(f"é¡¹ç›®å¥åº·æ£€æŸ¥å®Œæˆ: {health_result.get('health_status', 'unknown')}")
            
            return {
                "success": True,
                "health_check": health_result,
                "project_info": project_info,
                "health_score": health_result.get("health_score", 0),
                "health_status": health_result.get("health_status", "unknown"),
                "recommendations": self._generate_health_recommendations(health_result)
            }
            
        except Exception as e:
            logger.error(f"é¡¹ç›®å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "health_score": 0,
                "health_status": "error"
            }
    
    def _generate_health_recommendations(self, health_result: Dict[str, Any]) -> List[str]:
        """æ ¹æ®å¥åº·æ£€æŸ¥ç»“æœç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        missing_files = health_result.get("missing_files", [])
        missing_dirs = health_result.get("missing_directories", [])
        
        if missing_files:
            recommendations.append(f"ç¼ºå°‘å…³é”®æ–‡ä»¶: {', '.join(missing_files)}")
        
        if missing_dirs:
            recommendations.append(f"ç¼ºå°‘å¿…è¦ç›®å½•: {', '.join(missing_dirs)}")
        
        if not health_result.get("codelinter_available", False):
            recommendations.append("codelinterå·¥å…·ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        
        if not health_result.get("hvigor_available", False):
            recommendations.append("hvigorå·¥å…·ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        
        health_score = health_result.get("health_score", 0)
        if health_score < 50:
            recommendations.append("é¡¹ç›®ç»“æ„å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼Œå»ºè®®é‡æ–°åˆå§‹åŒ–")
        elif health_score < 80:
            recommendations.append("é¡¹ç›®ç»“æ„éœ€è¦å®Œå–„ï¼Œå»ºè®®è¡¥å……ç¼ºå¤±æ–‡ä»¶")
        
        return recommendations
    
    # ==================== MyApplication2ç»“æ„è¯»å–å’ŒéªŒè¯æ–¹æ³• ====================
    
    def _read_myapplication2_structure(self) -> str:
        """
        è¯»å–MyApplication2é¡¹ç›®ç»“æ„ä¿¡æ¯
        ä¸ºé¡¹ç›®ç®¡ç†Agentæä¾›è¯¦ç»†çš„é¡¹ç›®ç»“æ„çŸ¥è¯†å’Œå®é™…æ–‡ä»¶å†…å®¹
        """
        try:
            structure_info = """
é¸¿è’™åº”ç”¨é¡¹ç›®ç»“æ„(HarmonyOS NEXT Stageæ¨¡å‹):

MyApplication2/                              # é¡¹ç›®æ ¹ç›®å½•
â”œâ”€â”€ AppScope/                           # åº”ç”¨å…¨å±€ä¿¡æ¯
â”‚   â”œâ”€â”€ app.json5                        # åº”ç”¨å…¨å±€é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ resources/                       # åº”ç”¨å…¨å±€èµ„æº
â”œâ”€â”€ entry/                              # åº”ç”¨ä¸»æ¨¡å—
â”‚   â”œâ”€â”€ src/main/                        # ä¸»æºç ç›®å½•
â”‚   â”‚   â”œâ”€â”€ ets/                         # TypeScriptæºç ç›®å½•
â”‚   â”‚   â”‚   â”œâ”€â”€ pages/                   # é¡µé¢æ–‡ä»¶ç›®å½• (**é¡µé¢æ–‡ä»¶å¿…é¡»æ”¾åœ¨è¿™é‡Œ**)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Index.ets            # é¦–é¡µ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LoginPage.ets        # ç™»å½•é¡µé¢
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Index.ets    # åº”ç”¨å…¥å£é¡µé¢æ–‡ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ services/                # æœåŠ¡ç±»ç›®å½• (**æœåŠ¡æ–‡ä»¶æ”¾åœ¨è¿™é‡Œ**)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ApiService.ets       # APIæœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ entryability/            # åº”ç”¨å…¥å£èƒ½åŠ›
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EntryAbility.ets     # ä¸»å…¥å£èƒ½åŠ›
â”‚   â”‚   â”‚   â””â”€â”€ entrybackupability/      # å¤‡ä»½æ¢å¤èƒ½åŠ›
â”‚   â”‚   â”‚       â””â”€â”€ EntryBackupAbility.ets
â”‚   â”‚   â”œâ”€â”€ module.json5                 # æ¨¡å—é…ç½®æ–‡ä»¶
â”‚   â”‚   â””â”€â”€ resources/                   # æ¨¡å—èµ„æº
â”‚   â”‚       â””â”€â”€ base/element/            # åŸºç¡€èµ„æºå…ƒç´  (**èµ„æºæ–‡ä»¶æ”¾åœ¨è¿™é‡Œ**)
â”‚   â”‚           â”œâ”€â”€ string.json      # å­—ç¬¦ä¸²èµ„æº
â”‚   â”‚           â”œâ”€â”€ color.json       # é¢œè‰²èµ„æº
â”‚   â”‚           â””â”€â”€ float.json       # æµ®ç‚¹æ•°èµ„æº
â”‚   â”œâ”€â”€ build-profile.json5              # æ„å»ºé…ç½®
â”‚   â”œâ”€â”€ hvigorfile.ts                    # æ„å»ºè„šæœ¬
â”‚   â””â”€â”€ oh-package.json5                 # ä¾èµ–ç®¡ç†
â””â”€â”€ hvigorfile.ts                           # é¡¹ç›®æ„å»ºè„šæœ¬

**å…³é”®è·¯å¾„è§„åˆ™ï¼š**
1. é¡µé¢æ–‡ä»¶ï¼šMyApplication2/entry/src/main/ets/pages/
2. æœåŠ¡æ–‡ä»¶ï¼šMyApplication2/entry/src/main/ets/services/
3. èƒ½åŠ›æ–‡ä»¶ï¼šMyApplication2/entry/src/main/ets/entryability/
4. èµ„æºæ–‡ä»¶ï¼šMyApplication2/entry/src/main/resources/base/element/
5. æ¨¡å—é…ç½®ï¼šMyApplication2/entry/src/main/module.json5

**ä»£ç ç”Ÿæˆè¦æ±‚ï¼š**
- æ‰€æœ‰æ–‡ä»¶è·¯å¾„å¿…é¡»ä»¥"MyApplication2/"å¼€å¤´
- é¡µé¢ç»„ä»¶ä½¿ç”¨@Entryå’Œ@Componentè£…é¥°å™¨
- æœåŠ¡ç±»æä¾›æ•°æ®å¤„ç†å’Œä¸šåŠ¡é€»è¾‘
- èµ„æºæ–‡ä»¶ä½¿ç”¨JSONæ ¼å¼å­˜å‚¨å­—ç¬¦ä¸²ã€é¢œè‰²ç­‰èµ„æº
            """
            
            # å®é™…è¯»å–ç›®å½•ç»“æ„å’Œå…³é”®é…ç½®æ–‡ä»¶
            if self.myapplication2_path.exists():
                existing_files = self._scan_existing_files_with_content()
                structure_info += f"\n\nå½“å‰é¡¹ç›®å®é™…çŠ¶æ€ï¼š\n{existing_files}"
            else:
                structure_info += "\n\næ³¨æ„ï¼šMyApplication2é¡¹ç›®å°šä¸å­˜åœ¨ï¼Œéœ€è¦å…ˆåˆ›å»ºé¡¹ç›®ç»“æ„ã€‚"
            
            return structure_info
            
        except Exception as e:
            logger.error(f"è¯»å–MyApplication2ç»“æ„å¤±è´¥: {e}")
            return "æ— æ³•è¯»å–é¡¹ç›®ç»“æ„ä¿¡æ¯"
    
    def _read_readme_description(self) -> str:
        """è¯»å–README.mdæ–‡ä»¶ä¸­çš„è‡ªç„¶è¯­è¨€æè¿°"""
        try:
            readme_file_path = self.myapplication2_path / "README.md"
            
            if not readme_file_path.exists():
                logger.warning(f"README.mdæ–‡ä»¶ä¸å­˜åœ¨: {readme_file_path}")
                return ""
            
            with open(readme_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾è‡ªç„¶è¯­è¨€æè¿°éƒ¨åˆ†
            # å¯»æ‰¾åŒ…å«"è‡ªç„¶è¯­è¨€æè¿°"çš„éƒ¨åˆ†
            lines = content.split('\n')
            description_lines = []
            start_capturing = False
            
            for line in lines:
                if "è‡ªç„¶è¯­è¨€æè¿°" in line:
                    start_capturing = True
                    continue
                
                if start_capturing:
                    # å¦‚æœé‡åˆ°æ–°çš„markdownæ ‡é¢˜ï¼Œåœæ­¢æ•è·ï¼ˆä½†å…è®¸ç¬¬ä¸‰çº§æ ‡é¢˜ï¼‰
                    if line.strip().startswith('##') and not line.strip().startswith('###'):
                        break
                    
                    # è·³è¿‡ç©ºè¡Œå’Œmarkdownè¯­æ³•ï¼Œä½†ä¿ç•™å†…å®¹
                    if line.strip() and not line.strip().startswith('---'):
                        description_lines.append(line.strip())
            
            description = '\n'.join(description_lines)
            logger.info(f"ä»README.mdæå–è‡ªç„¶è¯­è¨€æè¿°: {len(description)} å­—ç¬¦")
            
            return description if description else content
            
        except Exception as e:
            logger.error(f"è¯»å–README.mdæ–‡ä»¶æè¿°å¤±è´¥: {e}")
            return ""
    
    def _read_project_files_content(self) -> Dict[str, str]:
        """è¯»å–é¡¹ç›®ä¸­çš„å…³é”®æ–‡ä»¶å†…å®¹ï¼Œç”¨äºæ›´å¥½çš„éœ€æ±‚åˆ†æ"""
        files_content = {}
        
        try:
            # è¯»å–å…³é”®é…ç½®æ–‡ä»¶
            config_files = [
                "oh-package.json5",
                "build-profile.json5",
                "entry/build-profile.json5",
                "entry/oh-package.json5",
                "entry/src/main/module.json5"
            ]
            
            for config_file in config_files:
                file_path = self.myapplication2_path / config_file
                if file_path.exists():
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            files_content[config_file] = f.read()
                    except Exception as e:
                        logger.warning(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
            
            # è¯»å–ç°æœ‰çš„ä»£ç æ–‡ä»¶
            code_dirs = [
                "entry/src/main/ets/pages",
                "entry/src/main/ets/services",
                "entry/src/main/ets/entryability"
            ]
            
            for code_dir in code_dirs:
                dir_path = self.myapplication2_path / code_dir
                if dir_path.exists():
                    for file_path in dir_path.glob("*.ets"):
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                relative_path = str(file_path.relative_to(self.myapplication2_path))
                                files_content[relative_path] = f.read()
                        except Exception as e:
                            logger.warning(f"è¯»å–ä»£ç æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            logger.info(f"æˆåŠŸè¯»å– {len(files_content)} ä¸ªé¡¹ç›®æ–‡ä»¶")
            return files_content
            
        except Exception as e:
            logger.error(f"è¯»å–é¡¹ç›®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def _get_project_context_for_llm(self) -> str:
        """ä¸ºLLMæä¾›é¡¹ç›®ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        try:
            project_files = self._read_project_files_content()
            
            if not project_files:
                return "é¡¹ç›®æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œæ— æ³•æä¾›é¡¹ç›®ä¸Šä¸‹æ–‡"
            
            context_parts = []
            context_parts.append("=== é¡¹ç›®æ–‡ä»¶å†…å®¹ ===")
            
            # é‡è¦æ–‡ä»¶ä¼˜å…ˆæ˜¾ç¤º
            priority_files = [
                "entry/src/main/ets/pages/Index.ets",
                "entry/src/main/module.json5",
                "entry/build-profile.json5"
            ]
            
            for file_path in priority_files:
                if file_path in project_files:
                    content = project_files[file_path]
                    context_parts.append(f"\n--- {file_path} ---")
                    context_parts.append(content[:1000])  # é™åˆ¶é•¿åº¦
            
            # å…¶ä»–æ–‡ä»¶
            for file_path, content in project_files.items():
                if file_path not in priority_files:
                    context_parts.append(f"\n--- {file_path} ---")
                    context_parts.append(content[:500])  # é™åˆ¶é•¿åº¦
            
            return "\n".join(context_parts)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆé¡¹ç›®ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return "é¡¹ç›®ä¸Šä¸‹æ–‡ç”Ÿæˆå¤±è´¥"
    
    def _scan_existing_files(self) -> str:
        """æ‰«æå­˜åœ¨çš„æ–‡ä»¶å¹¶è¿”å›ç»“æ„ä¿¡æ¯"""
        try:
            existing_files = []
            
            # æ‰«æä¸»è¦ç›®å½•
            main_dirs = [
                "entry/src/main/ets/pages",
                "entry/src/main/ets/services", 
                "entry/src/main/ets/entryability",
                "entry/src/main/resources/base/element"
            ]
            
            for dir_path in main_dirs:
                full_path = self.myapplication2_path / dir_path
                if full_path.exists():
                    files = list(full_path.glob("*"))
                    if files:
                        existing_files.append(f"  {dir_path}/: {', '.join([f.name for f in files if f.is_file()])}")
            
            return "\n".join(existing_files) if existing_files else "æœªæ‰¾åˆ°ç°æœ‰æ–‡ä»¶"
            
        except Exception as e:
            logger.error(f"æ‰«æç°æœ‰æ–‡ä»¶å¤±è´¥: {e}")
            return "æ— æ³•æ‰«æç°æœ‰æ–‡ä»¶"
    
    def _scan_existing_files_with_content(self) -> str:
        """æ‰«æå­˜åœ¨çš„æ–‡ä»¶å¹¶è¿”å›ç»“æ„ä¿¡æ¯ä»¥åŠå…³é”®æ–‡ä»¶å†…å®¹"""
        try:
            result = []
            
            # æ‰«æä¸»è¦ç›®å½•
            main_dirs = [
                "entry/src/main/ets/pages",
                "entry/src/main/ets/services", 
                "entry/src/main/ets/entryability",
                "entry/src/main/resources/base/element"
            ]
            
            files_found = 0
            for dir_path in main_dirs:
                full_path = self.myapplication2_path / dir_path
                if full_path.exists():
                    files = list(full_path.glob("*"))
                    file_names = [f.name for f in files if f.is_file()]
                    if file_names:
                        result.append(f"ğŸ“ {dir_path}/: {', '.join(file_names)}")
                        files_found += len(file_names)
            
            # è¯»å–å…³é”®é…ç½®æ–‡ä»¶å†…å®¹
            key_files = [
                ("entry/src/main/module.json5", "æ¨¡å—é…ç½®"),
                ("entry/src/main/resources/base/element/string.json", "å­—ç¬¦ä¸²èµ„æº"),
                ("entry/src/main/resources/base/element/color.json", "é¢œè‰²èµ„æº"),
                ("AppScope/app.json5", "åº”ç”¨é…ç½®")
            ]
            
            for file_path, description in key_files:
                full_path = self.myapplication2_path / file_path
                if full_path.exists():
                    try:
                        with open(full_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            # é™åˆ¶å†…å®¹é•¿åº¦ä»¥é¿å…è¿‡é•¿
                            if len(content) > 500:
                                content = content[:500] + "..."
                            result.append(f"ğŸ“„ {description} ({file_path}):")
                            result.append(f"```json\n{content}\n```")
                    except Exception as e:
                        result.append(f"ğŸ“„ {description} ({file_path}): è¯»å–å¤±è´¥ - {e}")
            
            # æ‰«æç°æœ‰çš„.etsæ–‡ä»¶å¹¶è¯»å–ç®€è¦å†…å®¹
            pages_dir = self.myapplication2_path / "entry/src/main/ets/pages"
            if pages_dir.exists():
                ets_files = list(pages_dir.glob("*.ets"))
                if ets_files:
                    result.append(f"\nğŸ“ ç°æœ‰é¡µé¢æ–‡ä»¶å†…å®¹é¢„è§ˆ:")
                    for ets_file in ets_files[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ–‡ä»¶
                        try:
                            with open(ets_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                                # æå–å…³é”®ä¿¡æ¯ï¼š@Entry, @Component, exportç­‰
                                lines = content.split('\n')
                                key_lines = []
                                for line in lines[:20]:  # åªçœ‹å‰20è¡Œ
                                    if any(keyword in line for keyword in ['@Entry', '@Component', 'export', 'import', 'struct']):
                                        key_lines.append(line.strip())
                                if key_lines:
                                    result.append(f"  ğŸ“„ {ets_file.name}:")
                                    result.append(f"    {'; '.join(key_lines[:5])}")
                        except Exception as e:
                            result.append(f"  ğŸ“„ {ets_file.name}: è¯»å–å¤±è´¥ - {e}")
            
            summary = f"æ€»è®¡å‘ç° {files_found} ä¸ªæ–‡ä»¶"
            if result:
                return f"{summary}\n\n" + "\n".join(result)
            else:
                return "æœªæ‰¾åˆ°ç°æœ‰æ–‡ä»¶"
            
        except Exception as e:
            logger.error(f"æ‰«ææ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            return "æ— æ³•æ‰«ææ–‡ä»¶å†…å®¹"
    
    def _validate_and_fix_file_paths(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        éªŒè¯å¹¶ä¿®å¤æ–‡ä»¶è·¯å¾„ï¼Œå•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼ä¸‹å¼ºåˆ¶åªè¿”å›Index.etsæ–‡ä»¶
        """
        try:
            # å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼ï¼šå¼ºåˆ¶åªè¿”å›Index.etsæ–‡ä»¶
            fixed_files = [{
                "path": "MyApplication2/entry/src/main/ets/pages/Index.ets",
                "type": "page",
                "purpose": "åº”ç”¨å…¥å£é¡µé¢ç»„ä»¶",
                "content_outline": "åŒ…å«@Entry @Componentè£…é¥°å™¨ã€é¡µé¢çŠ¶æ€ç®¡ç†ã€UIæ˜¾ç¤ºç»„ä»¶",
                "key_components": analysis_data.get("planned_files", [{}])[0].get("key_components", []),
                "dependencies": analysis_data.get("planned_files", [{}])[0].get("dependencies", [])
            }]
            
            logger.info(f"å•ä¸ªæ–‡ä»¶ç”Ÿæˆæ¨¡å¼: å¼ºåˆ¶è®¾ç½®ä¸ºIndex.etsæ–‡ä»¶")
            logger.info(f"ç›®æ ‡æ–‡ä»¶è·¯å¾„: MyApplication2/entry/src/main/ets/pages/Index.ets")
            
            # æ›´æ–°åˆ†ææ•°æ®
            analysis_data["planned_files"] = fixed_files
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"éªŒè¯æ–‡ä»¶è·¯å¾„å¤±è´¥: {e}")
            return analysis_data
    
    def _fix_file_path(self, original_path: str, file_type: str) -> str:
        """
        ä¿®å¤å•ä¸ªæ–‡ä»¶è·¯å¾„ï¼Œç¡®ä¿åœ¨æ­£ç¡®çš„MyApplication2ç›®å½•ä¸­
        """
        try:
            # å¦‚æœå·²ç»ä»¥MyApplication2å¼€å¤´ï¼Œæ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®
            if original_path.startswith("MyApplication2/"):
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦ç¬¦åˆè§„èŒƒ
                if self._is_valid_harmonyos_path(original_path, file_type):
                    return original_path
            
            # æå–æ–‡ä»¶å
            import os
            filename = os.path.basename(original_path) if original_path else "GeneratedFile.ets"
            if not filename.endswith(".ets") and file_type == "arkts":
                filename = filename + ".ets"
            elif not filename.endswith(".json") and file_type == "json":
                filename = filename + ".json"
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹å†³å®šæ­£ç¡®è·¯å¾„
            if file_type == "arkts":
                if "Page" in filename or "page" in filename.lower():
                    return f"MyApplication2/entry/src/main/ets/pages/{filename}"
                elif "Service" in filename or "service" in filename.lower():
                    return f"MyApplication2/entry/src/main/ets/services/{filename}"
                elif "Ability" in filename:
                    return f"MyApplication2/entry/src/main/ets/entryability/{filename}"
                else:
                    # é»˜è®¤æ”¾åœ¨pagesç›®å½•
                    return f"MyApplication2/entry/src/main/ets/pages/{filename}"
            elif file_type == "json":
                return f"MyApplication2/entry/src/main/resources/base/element/{filename}"
            else:
                # é»˜è®¤æ”¾åœ¨pagesç›®å½•
                return f"MyApplication2/entry/src/main/ets/pages/{filename}"
                
        except Exception as e:
            logger.error(f"ä¿®å¤æ–‡ä»¶è·¯å¾„å¤±è´¥: {e}")
            return f"MyApplication2/entry/src/main/ets/pages/GeneratedFile.ets"
    
    def _is_valid_harmonyos_path(self, path: str, file_type: str) -> bool:
        """
        æ£€æŸ¥è·¯å¾„æ˜¯å¦ç¬¦åˆHarmonyOSé¡¹ç›®è§„èŒƒ
        """
        valid_patterns = [
            "MyApplication2/entry/src/main/ets/pages/",
            "MyApplication2/entry/src/main/ets/services/",
            "MyApplication2/entry/src/main/ets/entryability/",
            "MyApplication2/entry/src/main/ets/entrybackupability/",
            "MyApplication2/entry/src/main/resources/base/element/"
        ]
        
        return any(path.startswith(pattern) for pattern in valid_patterns)
    
    # ==================== é”™è¯¯åˆ†ææ–¹æ³• ====================
    
    async def _analyze_errors_and_plan_fixes(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯å¹¶åˆ¶å®šä¿®å¤ç­–ç•¥"""
        try:
            current_errors = params.get("current_errors", [])
            affected_files = params.get("affected_files", [])
            error_types = params.get("error_types", [])
            fix_attempt = params.get("fix_attempt", 0)
            existing_files = params.get("existing_files", [])
            
            logger.info(f"é”™è¯¯åˆ†æå¼€å§‹: {len(current_errors)} ä¸ªé”™è¯¯")
            logger.info(f"å—å½±å“æ–‡ä»¶: {affected_files}")
            logger.info(f"é”™è¯¯ç±»å‹: {error_types}")
            logger.info(f"ä¿®å¤å°è¯•æ¬¡æ•°: {fix_attempt}")
            
            if not current_errors:
                return {
                    "success": True,
                    "message": "æ²¡æœ‰é”™è¯¯éœ€è¦åˆ†æ",
                    "fix_strategies": []
                }
            
            # è¯»å–é¡¹ç›®ç»“æ„
            project_structure = self._read_myapplication2_structure()
            
            # æ„å»ºé”™è¯¯åˆ†ææç¤ºè¯
            error_summary = "\n".join([
                f"é”™è¯¯{i+1}: æ–‡ä»¶={error.get('file_path', 'unknown')}, ç±»å‹={error.get('error_type', 'unknown')}, æ¶ˆæ¯={error.get('message', '')[:100]}"
                for i, error in enumerate(current_errors[:5])  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            ])
            
            existing_files_info = "\n".join([
                f"æ–‡ä»¶{i+1}: {file_info.get('path', 'unknown')} (çŠ¶æ€: {file_info.get('status', 'unknown')})"
                for i, file_info in enumerate(existing_files[:5])  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
            ])
            
            analysis_prompt = f"""ä½œä¸ºé¸¿è’™åº”ç”¨é¡¹ç›®ç®¡ç†ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹ç¼–è¯‘å’Œé™æ€æ£€æŸ¥é”™è¯¯ï¼Œå¹¶åˆ¶å®šä¿®å¤ç­–ç•¥ã€‚

é¡¹ç›®ç»“æ„ä¿¡æ¯:
{project_structure}

å½“å‰é”™è¯¯ä¿¡æ¯:
{error_summary}

ç°æœ‰æ–‡ä»¶ä¿¡æ¯:
{existing_files_info}

ä¿®å¤å°è¯•æ¬¡æ•°: {fix_attempt}

è¯·æ‰§è¡Œä»¥ä¸‹åˆ†æï¼š
1. é”™è¯¯åˆ†ç±»ï¼šå°†é”™è¯¯æŒ‰ç±»å‹å’Œæ–‡ä»¶åˆ†ç»„
2. æ ¹å› åˆ†æï¼šåˆ†æé”™è¯¯çš„æ ¹æœ¬åŸå› 
3. ä¿®å¤ç­–ç•¥ï¼šåˆ¶å®šå…·ä½“çš„ä¿®å¤ç­–ç•¥
4. æ–‡ä»¶å®šä½ï¼šç¡®å®šéœ€è¦ä¿®å¤çš„å‡†ç¡®æ–‡ä»¶è·¯å¾„

**é‡è¦è¦æ±‚ï¼š**
- æ‰€æœ‰æ–‡ä»¶è·¯å¾„å¿…é¡»ä»¥"MyApplication2/"å¼€å¤´
- ç¡®ä¿æ–‡ä»¶è·¯å¾„å‡†ç¡®ï¼Œé¿å…ç”Ÿæˆåœ¨é”™è¯¯ä½ç½®
- ä¼˜å…ˆä¿®å¤ç¼–è¯‘é”™è¯¯ï¼Œå†å¤„ç†é™æ€æ£€æŸ¥é”™è¯¯
- æä¾›å…·ä½“çš„ä¿®å¤æŒ‡å¯¼

è¾“å‡ºæ ¼å¼(JSON)ï¼š
{{
  "error_analysis": {{
    "total_errors": {len(current_errors)},
    "error_groups": [
      {{
        "file_path": "MyApplication2/entry/src/main/ets/pages/LoginPage.ets",
        "error_type": "compile",
        "error_count": 2,
        "priority": "high"
      }}
    ],
    "root_causes": ["åŸå› 1", "åŸå› 2"]
  }},
  "fix_strategies": [
    {{
      "target_file": "MyApplication2/entry/src/main/ets/pages/LoginPage.ets",
      "strategy": "ä¿®å¤å¯¼å…¥è¯­å¥é”™è¯¯",
      "specific_actions": ["ä¿®æ”¹å¯¼å…¥è·¯å¾„", "æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥"],
      "priority": "high"
    }}
  ]
}}"""

            if self.llm:
                messages = [{"role": "user", "content": analysis_prompt}]
                response = self.llm.chat(messages)
                content = self.llm.remove_think(response.content)
                
                # å°è¯•è§£æJSON
                import json
                try:
                    analysis_data = json.loads(content)
                    # éªŒè¯å’Œä¿®å¤æ–‡ä»¶è·¯å¾„
                    analysis_data = self._validate_fix_strategies(analysis_data)
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç”ŸæˆåŸºç¡€åˆ†æ
                    analysis_data = self._generate_basic_error_analysis(current_errors, affected_files)
            else:
                # æ²¡æœ‰LLMæ—¶çš„å¤‡ç”¨åˆ†æ
                analysis_data = self._generate_basic_error_analysis(current_errors, affected_files)
            
            logger.info(f"é”™è¯¯åˆ†æå®Œæˆï¼Œç”Ÿæˆäº†{len(analysis_data.get('fix_strategies', []))}ä¸ªä¿®å¤ç­–ç•¥")
            
            return {
                "success": True,
                "analysis": analysis_data,
                "fix_strategies": analysis_data.get("fix_strategies", []),
                "error_analysis": analysis_data.get("error_analysis", {}),
                "project_path": "MyApplication2"
            }
                
        except Exception as e:
            logger.error(f"é”™è¯¯åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "fix_strategies": []
            }
    
    def _validate_fix_strategies(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å’Œä¿®å¤ç­–ç•¥ä¸­çš„æ–‡ä»¶è·¯å¾„"""
        try:
            fix_strategies = analysis_data.get("fix_strategies", [])
            validated_strategies = []
            
            for strategy in fix_strategies:
                target_file = strategy.get("target_file", "")
                
                # éªŒè¯å’Œä¿®å¤æ–‡ä»¶è·¯å¾„
                if target_file and not target_file.startswith("MyApplication2/"):
                    # å°è¯•ä¿®å¤è·¯å¾„
                    if target_file.endswith(".ets"):
                        if "Page" in target_file or "page" in target_file.lower():
                            target_file = f"MyApplication2/entry/src/main/ets/pages/{os.path.basename(target_file)}"
                        else:
                            target_file = f"MyApplication2/entry/src/main/ets/services/{os.path.basename(target_file)}"
                    elif target_file.endswith(".json"):
                        target_file = f"MyApplication2/entry/src/main/resources/base/element/{os.path.basename(target_file)}"
                    
                    logger.info(f"ä¿®å¤ç­–ç•¥æ–‡ä»¶è·¯å¾„: {strategy.get('target_file', '')} -> {target_file}")
                    strategy["target_file"] = target_file
                
                validated_strategies.append(strategy)
            
            analysis_data["fix_strategies"] = validated_strategies
            return analysis_data
            
        except Exception as e:
            logger.error(f"éªŒè¯ä¿®å¤ç­–ç•¥å¤±è´¥: {e}")
            return analysis_data
    
    def _generate_basic_error_analysis(self, current_errors: List[Dict], affected_files: List[str]) -> Dict[str, Any]:
        """ç”ŸæˆåŸºç¡€é”™è¯¯åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            # æŒ‰æ–‡ä»¶åˆ†ç»„é”™è¯¯
            error_groups = {}
            for error in current_errors:
                file_path = error.get("file_path", "unknown")
                error_type = error.get("error_type", "unknown")
                
                # ä¿®å¤æ–‡ä»¶è·¯å¾„
                if file_path == "unknown" or not file_path.startswith("MyApplication2/"):
                    file_path = "MyApplication2/entry/src/main/ets/pages/Index.ets"
                
                if file_path not in error_groups:
                    error_groups[file_path] = {"compile": 0, "lint": 0}
                
                error_groups[file_path][error_type] = error_groups[file_path].get(error_type, 0) + 1
            
            # ç”Ÿæˆä¿®å¤ç­–ç•¥
            fix_strategies = []
            for file_path, error_counts in error_groups.items():
                total_errors = sum(error_counts.values())
                strategy = {
                    "target_file": file_path,
                    "strategy": f"ä¿®å¤{file_path}ä¸­çš„{total_errors}ä¸ªé”™è¯¯",
                    "specific_actions": ["æ£€æŸ¥è¯­æ³•é”™è¯¯", "ä¿®å¤å¯¼å…¥è¯­å¥", "éªŒè¯ç±»å‹å®šä¹‰"],
                    "priority": "high" if error_counts.get("compile", 0) > 0 else "medium"
                }
                fix_strategies.append(strategy)
            
            return {
                "error_analysis": {
                    "total_errors": len(current_errors),
                    "error_groups": [
                        {
                            "file_path": file_path,
                            "error_type": "mixed",
                            "error_count": sum(counts.values()),
                            "priority": "high"
                        }
                        for file_path, counts in error_groups.items()
                    ],
                    "root_causes": ["è¯­æ³•é”™è¯¯", "å¯¼å…¥é—®é¢˜", "ç±»å‹å®šä¹‰é—®é¢˜"]
                },
                "fix_strategies": fix_strategies
            }
            
        except Exception as e:
            logger.error(f"ç”ŸæˆåŸºç¡€é”™è¯¯åˆ†æå¤±è´¥: {e}")
            return {
                "error_analysis": {"total_errors": len(current_errors)},
                "fix_strategies": []
            }
    
    async def _analyze_errors_and_generate_keywords(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯ä¿¡æ¯å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯"""
        try:
            errors = params.get("errors", [])
            original_requirement = params.get("original_requirement", "")
            project_path = params.get("project_path", "MyApplication2")
            
            logger.info(f"å¼€å§‹åˆ†æé”™è¯¯å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯: {len(errors)} ä¸ªé”™è¯¯")
            
            if not errors:
                return {
                    "success": True,
                    "search_keywords": ["é¸¿è’™å¼€å‘", "ArkTS", "HarmonyOS"],
                    "error_analysis": "æœªæ£€æµ‹åˆ°å…·ä½“é”™è¯¯"
                }
            
            # å°†æ‰€æœ‰é”™è¯¯ä¿¡æ¯è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            error_text = "\n".join([str(error) for error in errors])
            
            prompt = f"""ä½œä¸ºé¸¿è’™å¼€å‘ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹é”™è¯¯ä¿¡æ¯å¹¶ç”Ÿæˆ5-8ä¸ªæœç´¢å…³é”®è¯ï¼Œç”¨äºæœç´¢è§£å†³æ–¹æ¡ˆã€‚

åŸå§‹éœ€æ±‚: {original_requirement}
é¡¹ç›®: {project_path}

é”™è¯¯ä¿¡æ¯:
{error_text}

è¯·ç”Ÿæˆèƒ½å¸®åŠ©ä¿®å¤è¿™äº›é”™è¯¯çš„æœç´¢å…³é”®è¯ï¼Œé‡ç‚¹å…³æ³¨:
1. é¸¿è’™/ArkTSç›¸å…³çš„è§£å†³æ–¹æ¡ˆ
2. å…·ä½“çš„é”™è¯¯ç±»å‹å’Œä¿®å¤æ–¹æ³•
3. ç›¸å…³çš„æŠ€æœ¯æ–‡æ¡£å’Œæœ€ä½³å®è·µ

ç›´æ¥è¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚:
ArkTSè¯­æ³•é”™è¯¯ä¿®å¤, é¸¿è’™å¯¼å…¥æ¨¡å—é—®é¢˜, HarmonyOSç¼–è¯‘é”™è¯¯è§£å†³, é¸¿è’™ç»„ä»¶è£…é¥°å™¨ç”¨æ³•"""

            if self.llm:
                messages = [{"role": "user", "content": prompt}]
                response = self.llm.chat(messages)
                content = self.llm.remove_think(response.content).strip()
                
                # è§£æå…³é”®è¯
                keywords = [kw.strip() for kw in content.split(',') if kw.strip()]
                
                if not keywords:
                    keywords = ["é¸¿è’™å¼€å‘é—®é¢˜", "ArkTSé”™è¯¯ä¿®å¤", "HarmonyOSä»£ç é—®é¢˜"]
                
                logger.info(f"ç”Ÿæˆæœç´¢å…³é”®è¯: {keywords}")
                
                return {
                    "success": True,
                    "search_keywords": keywords,
                    "error_analysis": f"åˆ†æäº† {len(errors)} ä¸ªé”™è¯¯",
                    "fix_strategy": "æ ¹æ®æœç´¢ç»“æœåˆ¶å®šä¿®å¤æ–¹æ¡ˆ"
                }
            else:
                return {
                    "success": False,
                    "error": "LLMæœªåˆå§‹åŒ–"
                }
                
        except Exception as e:
            logger.error(f"åˆ†æé”™è¯¯å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }