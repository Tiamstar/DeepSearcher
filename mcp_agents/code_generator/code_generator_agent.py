#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Code Generator Agent
åä¸ºå¤šAgentåä½œç³»ç»Ÿ - ä»£ç ç”ŸæˆAgent
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

# ç¡®ä¿åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

from typing import Dict, Any, List
from datetime import datetime

from mcp_agents.base import MCPAgent, MCPMessage
from deepsearcher.llm.base import BaseLLM
from deepsearcher.llm import DeepSeek, OpenAI, Anthropic

# ç§»é™¤ç¡¬ç¼–ç æ¨¡æ¿ï¼Œè®©LLMæ ¹æ®éœ€æ±‚å®Œå…¨ç”Ÿæˆä»£ç 


class CodeGeneratorAgent(MCPAgent):
    """ä»£ç ç”ŸæˆAgent - è´Ÿè´£æ ¹æ®éœ€æ±‚å’Œæœç´¢ç»“æœç”Ÿæˆä»£ç """
    
    def __init__(self, config: Dict[str, Any] = None):
        super().__init__("code_generator")
        self.config = config or {}
        self.llm_config = self.config.get("llm_config", {})
        self.llm_client = None
        self.temperature = 0.7
        self.max_tokens = 16000
        
        # é¡¹ç›®è·¯å¾„é…ç½®
        from pathlib import Path
        self.project_root = Path(__file__).parent.parent.parent
        self.myapplication2_path = self.project_root / "MyApplication2"
        
        # å£°æ˜èƒ½åŠ›
        self.declare_capability("code.generate", {
            "description": "æ ¹æ®éœ€æ±‚å’Œä¸Šä¸‹æ–‡ç”Ÿæˆä»£ç ",
            "parameters": ["requirement", "context", "language", "framework"]
        })
        self.declare_capability("code.template", {
            "description": "ç”Ÿæˆä»£ç æ¨¡æ¿",
            "parameters": ["template_type", "language", "parameters"]
        })
        self.declare_capability("code.optimize", {
            "description": "ä¼˜åŒ–ç°æœ‰ä»£ç ", 
            "parameters": ["code", "optimization_type", "language"]
        })
        
        # æ–°å¢é¸¿è’™ä¸“ç”¨èƒ½åŠ›
        self.declare_capability("code.generate_harmonyos", {
            "description": "ç”Ÿæˆé¸¿è’™ArkTSä»£ç ",
            "parameters": ["requirement", "context", "target_files", "project_path", "is_fixing", "previous_errors"]
        })
    
    async def initialize(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–ä»£ç ç”ŸæˆAgent"""
        try:
            # è·å–LLMé…ç½®
            if not self.llm_config or not self.llm_config.get("provider"):
                # å¦‚æœæ²¡æœ‰ä¼ å…¥LLMé…ç½®ï¼Œä»é…ç½®åŠ è½½å™¨è·å–
                from shared.config_loader import ConfigLoader
                config_loader = ConfigLoader()
                self.llm_config = config_loader.get_llm_config("code_generator")
                self.logger.info("ä»é…ç½®åŠ è½½å™¨è·å–LLMé…ç½®")
            
            # è·å–é…ç½®ä¿¡æ¯
            provider = self.llm_config.get("provider", "")
            llm_type = self.llm_config.get("type", provider.lower())
            model = self.llm_config.get("model", "")
            api_key = self.llm_config.get("api_key", "")
            base_url = self.llm_config.get("base_url", "")
            temperature = self.llm_config.get("temperature", 0.7)
            max_tokens = self.llm_config.get("max_tokens", 16000)
            
            
            
            if llm_type.lower() == "deepseek":
                # ç¡®ä¿æœ‰APIå¯†é’¥
                if not api_key:
                    api_key = os.getenv("DEEPSEEK_API_KEY")
                if not api_key:
                    raise ValueError("LLM APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")
                
                self.llm_client = DeepSeek(
                    api_key=api_key,
                    base_url=base_url or "https://api.deepseek.com",
                    model=model or "deepseek-coder"
                )
                self.temperature = temperature
                self.max_tokens = max_tokens
            elif llm_type.lower() == "openai":
                # ç¡®ä¿æœ‰APIå¯†é’¥
                if not api_key:
                    api_key = os.getenv("OPENAI_API_KEY")
                if not api_key:
                    raise ValueError("LLM APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡")
                
                self.llm_client = OpenAI(
                    api_key=api_key,
                    base_url=base_url,
                    model=model or "gpt-3.5-turbo"
                )
                self.temperature = temperature
                self.max_tokens = max_tokens
            elif llm_type.lower() == "anthropic":
                # ç¡®ä¿æœ‰APIå¯†é’¥ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„å¯†é’¥ï¼‰
                if not api_key:
                    api_key = os.getenv("ANTHROPIC_API_KEY")
                if not api_key:
                    raise ValueError("LLM APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®api_keyæˆ–è®¾ç½®ç¯å¢ƒå˜é‡")
                
                self.llm_client = Anthropic(
                    api_key=api_key,
                    base_url=base_url,
                    model=model or "claude-3-haiku-20240307"
                )
                # ä¿å­˜temperatureå’Œmax_tokenså‚æ•°ç”¨äºåç»­è°ƒç”¨
                self.temperature = temperature
                self.max_tokens = max_tokens
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„LLMç±»å‹: {llm_type}")
            
            self.logger.info(f"ä»£ç ç”ŸæˆAgentåˆå§‹åŒ–æˆåŠŸ")
            
            return {
                "agent_id": self.agent_id,
                "capabilities": self.capabilities,
                "llm_type": llm_type,
                "llm_provider": provider,
                "llm_model": model,
                "supported_languages": ["python", "javascript", "typescript", "arkts", "cpp", "java", "go"],
                "initialized_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"ä»£ç ç”ŸæˆAgentåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def handle_request(self, message: MCPMessage) -> MCPMessage:
        """å¤„ç†ä»£ç ç”Ÿæˆç›¸å…³è¯·æ±‚"""
        try:
            method = message.method
            params = message.params or {}
            
            if method == "code.generate":
                result = await self._generate_code(params)
                return self.protocol.create_response(message.id, result)
            
            elif method == "code.template":
                result = await self._generate_template(params)
                return self.protocol.create_response(message.id, result)
            
            elif method == "code.optimize":
                result = await self._optimize_code(params)
                return self.protocol.create_response(message.id, result)
            
            elif method == "code.generate_harmonyos":
                result = await self._generate_harmonyos_code(params)
                return self.protocol.create_response(message.id, result)
            
            else:
                return self.protocol.handle_method_not_found(message.id, method)
                
        except Exception as e:
            self.logger.error(f"å¤„ç†ä»£ç ç”Ÿæˆè¯·æ±‚å¤±è´¥: {str(e)}")
            return self.protocol.handle_internal_error(message.id, str(e))
    
    async def _generate_code(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä»£ç """
        requirement = params.get("requirement", "")
        context = params.get("context", "")
        language = params.get("language", "python")
        framework = params.get("framework", "")
        
        if not requirement:
            raise ValueError("éœ€æ±‚æè¿°ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºä»£ç ç”Ÿæˆæç¤ºè¯
        system_prompt = self._build_code_generation_prompt(language, framework)
        
        user_prompt = f"""éœ€æ±‚æè¿°ï¼š{requirement}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š{context}

è¯·æ ¹æ®éœ€æ±‚ç”Ÿæˆ{language}ä»£ç ï¼Œç¡®ä¿ä»£ç ï¼š
1. ç¬¦åˆæœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ
2. åŒ…å«å¿…è¦çš„æ³¨é‡Šå’Œæ–‡æ¡£
3. å¤„ç†å¼‚å¸¸æƒ…å†µ
4. å¯è¯»æ€§å¼ºï¼Œç»“æ„æ¸…æ™°
5. å¦‚æœæ˜¯åä¸ºç›¸å…³å¼€å‘ï¼Œè¯·éµå¾ªåä¸ºå¼€å‘è§„èŒƒ

é‡è¦ï¼šè¯·åªè¾“å‡ºçº¯ArkTSä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•markdownæ ¼å¼ã€è¯´æ˜æ–‡å­—æˆ–è§£é‡Šã€‚
è¾“å‡ºæ ¼å¼ï¼šç›´æ¥è¾“å‡ºArkTSä»£ç ï¼Œä»importè¯­å¥æˆ–æ³¨é‡Šå¼€å§‹ï¼Œåˆ°æœ€åçš„}}ç»“æŸã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            response = self.llm_client.chat(messages)
            generated_code = self._extract_code_from_response(response.content)
            
            result = {
                "requirement": requirement,
                "language": language,
                "framework": framework,
                "generated_code": generated_code,
                "raw_response": response.content,
                "token_usage": response.total_tokens,
                "agent_id": self.agent_id,
                "generated_at": datetime.now().isoformat(),
                "metadata": {
                    "code_length": len(generated_code),
                    "estimated_lines": len(generated_code.split('\n')),
                    "context_provided": bool(context)
                }
            }
            
            self.logger.info(f"ä»£ç ç”Ÿæˆå®Œæˆï¼Œè¯­è¨€: {language}")
            return result
            
        except Exception as e:
            self.logger.error(f"ä»£ç ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise
    
    async def _generate_template(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä»£ç æ¨¡æ¿"""
        template_type = params.get("template_type", "")
        language = params.get("language", "python")
        template_params = params.get("parameters", {})
        
        if not template_type:
            raise ValueError("æ¨¡æ¿ç±»å‹ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºæ¨¡æ¿ç”Ÿæˆæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{language}ä»£ç æ¨¡æ¿ç”Ÿæˆå™¨ã€‚
        
è¯·å‚è€ƒæŒ‡å®šçš„æ¨¡æ¿ç±»å‹ç”Ÿæˆæ ‡å‡†çš„ä»£ç æ¨¡æ¿ï¼ŒåŒ…å«ï¼š
1. åŸºç¡€ç»“æ„å’Œæ¡†æ¶
2. å¸¸ç”¨çš„æ–¹æ³•å’Œå±æ€§
3. å¿…è¦çš„æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²
4. é”™è¯¯å¤„ç†æœºåˆ¶
5. æœ€ä½³å®è·µç¤ºä¾‹

æ¨¡æ¿ä¸å¯ç›´æ¥ä½¿ç”¨"""
        
        user_prompt = f"""æ¨¡æ¿ç±»å‹ï¼š{template_type}
ç¼–ç¨‹è¯­è¨€ï¼š{language}
æ¨¡æ¿å‚æ•°ï¼š{template_params}

è¯·ç”Ÿæˆå¯¹åº”çš„ä»£ç æ¨¡æ¿ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            response = self.llm_client.chat(messages)
            template_code = self._extract_code_from_response(response.content)
            
            result = {
                "template_type": template_type,
                "language": language,
                "parameters": template_params,
                "template_code": template_code,
                "raw_response": response.content,
                "token_usage": response.total_tokens,
                "agent_id": self.agent_id,
                "generated_at": datetime.now().isoformat(),
                "usage_instructions": self._generate_usage_instructions(template_type, language)
            }
            
            self.logger.info(f"ä»£ç æ¨¡æ¿ç”Ÿæˆå®Œæˆï¼Œç±»å‹: {template_type}")
            return result
            
        except Exception as e:
            self.logger.error(f"ä»£ç æ¨¡æ¿ç”Ÿæˆå¤±è´¥: {str(e)}")
            raise
    
    async def _optimize_code(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼˜åŒ–ä»£ç """
        code = params.get("code", "")
        optimization_type = params.get("optimization_type", "general")
        language = params.get("language", "python")
        
        if not code:
            raise ValueError("ä»£ç å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # æ„å»ºä»£ç ä¼˜åŒ–æç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{language}ä»£ç ä¼˜åŒ–ä¸“å®¶ã€‚

è¯·å¯¹æä¾›çš„ä»£ç è¿›è¡Œä¼˜åŒ–ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. æ€§èƒ½ä¼˜åŒ–
2. ä»£ç å¯è¯»æ€§
3. å†…å­˜ä½¿ç”¨æ•ˆç‡
4. é”™è¯¯å¤„ç†
5. ä»£ç ç»“æ„å’Œç»„ç»‡
6. æœ€ä½³å®è·µåº”ç”¨

ä¼˜åŒ–ç±»å‹ï¼š{optimization_type}

è¯·æä¾›ä¼˜åŒ–åçš„ä»£ç ï¼Œå¹¶è¯´æ˜ä¸»è¦çš„ä¼˜åŒ–ç‚¹ã€‚"""
        
        user_prompt = f"""éœ€è¦ä¼˜åŒ–çš„{language}ä»£ç ï¼š

```{language}
{code}
```

è¯·è¿›è¡Œ{optimization_type}ä¼˜åŒ–ã€‚"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            response = self.llm_client.chat(messages)
            optimized_code = self._extract_code_from_response(response.content)
            optimization_notes = self._extract_optimization_notes(response.content)
            
            result = {
                "original_code": code,
                "optimized_code": optimized_code,
                "optimization_type": optimization_type,
                "language": language,
                "optimization_notes": optimization_notes,
                "raw_response": response.content,
                "token_usage": response.total_tokens,
                "agent_id": self.agent_id,
                "optimized_at": datetime.now().isoformat(),
                "improvement_metrics": {
                    "original_lines": len(code.split('\n')),
                    "optimized_lines": len(optimized_code.split('\n')),
                    "size_change": len(optimized_code) - len(code)
                }
            }
            
            self.logger.info(f"ä»£ç ä¼˜åŒ–å®Œæˆï¼Œç±»å‹: {optimization_type}")
            return result
            
        except Exception as e:
            self.logger.error(f"ä»£ç ä¼˜åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def _build_code_generation_prompt(self, language: str, framework: str) -> str:
        """æ„å»ºä»£ç ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
        base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„{language}å¼€å‘ä¸“å®¶ï¼Œæ“…é•¿ç¼–å†™é«˜è´¨é‡ã€å¯ç»´æŠ¤çš„ä»£ç ã€‚"""
        
        if framework:
            base_prompt += f"ä½ ç‰¹åˆ«ç†Ÿæ‚‰{framework}æ¡†æ¶çš„å¼€å‘ã€‚"
        
        if language.lower() == "arkts":
            base_prompt += """
ä½ ä¸“ç²¾äºåä¸ºArkTSå¼€å‘ï¼Œç†Ÿæ‚‰ï¼š
- ArkTSè¯­æ³•å’Œç‰¹æ€§
- åä¸ºé¸¿è’™å¼€å‘è§„èŒƒ
- ArkUIç»„ä»¶å¼€å‘
- çŠ¶æ€ç®¡ç†å’Œæ•°æ®ç»‘å®š
- åä¸ºè®¾å¤‡é€‚é…
"""
        elif language.lower() == "cpp":
            base_prompt += """
ä½ ä¸“ç²¾äºC++å¼€å‘ï¼Œç†Ÿæ‚‰ï¼š
- ç°ä»£C++ç‰¹æ€§ï¼ˆC++11/14/17/20ï¼‰
- å†…å­˜ç®¡ç†å’ŒRAII
- STLå®¹å™¨å’Œç®—æ³•
- å¤šçº¿ç¨‹ç¼–ç¨‹
- æ€§èƒ½ä¼˜åŒ–
"""
        elif language.lower() == "python":
            base_prompt += """
ä½ ä¸“ç²¾äºPythonå¼€å‘ï¼Œç†Ÿæ‚‰ï¼š
- Pythonæœ€ä½³å®è·µå’ŒPEPè§„èŒƒ
- å¼‚æ­¥ç¼–ç¨‹å’Œå¹¶å‘
- æ•°æ®å¤„ç†å’Œç§‘å­¦è®¡ç®—
- Webå¼€å‘æ¡†æ¶
- æµ‹è¯•é©±åŠ¨å¼€å‘
"""
        
        base_prompt += """
è¯·ç¡®ä¿ç”Ÿæˆçš„ä»£ç ï¼š
1. éµå¾ªè¯­è¨€çš„æœ€ä½³å®è·µå’Œç¼–ç è§„èŒƒ
2. åŒ…å«é€‚å½“çš„é”™è¯¯å¤„ç†
3. æœ‰æ¸…æ™°çš„æ³¨é‡Šå’Œæ–‡æ¡£
4. ç»“æ„è‰¯å¥½ï¼Œæ˜“äºç»´æŠ¤
5. è€ƒè™‘æ€§èƒ½å’Œå®‰å…¨æ€§
"""
        
        return base_prompt
    
    def _extract_code_from_response(self, response: str) -> str:
        """ä»LLMå“åº”ä¸­æå–çº¯ä»£ç """
        # ç§»é™¤æ€è€ƒæ ‡ç­¾
        response = BaseLLM.remove_think(response)
        
        import re
        
        # 1. é¦–å…ˆå°è¯•æå–ä»£ç å—
        code_patterns = [
            r'```(?:arkts|typescript|ets|ts)?\s*\n(.*?)\n```',
            r'```\s*\n(.*?)\n```',
            r'```(.*?)```'
        ]
        
        extracted_code = ""
        for pattern in code_patterns:
            matches = re.findall(pattern, response, re.DOTALL)
            if matches:
                extracted_code = matches[0].strip()
                break
        
        # å¦‚æœæ²¡æœ‰ä»ä»£ç å—ä¸­æå–åˆ°ï¼Œåˆ™ä½¿ç”¨æ•´ä¸ªå“åº”
        if not extracted_code:
            extracted_code = response.strip()
        
        # 2. æ¸…ç†ä»£ç  - ç§»é™¤ä¸­æ–‡å†…å®¹å’Œéä»£ç éƒ¨åˆ†
        lines = extracted_code.split('\n')
        clean_lines = []
        
        # ç”¨äºæ£€æµ‹ä»£ç æ®µçš„æ ‡å¿—
        has_found_import = False
        has_found_entry = False
        has_found_component = False
        in_code_section = False
        
        for line in lines:
            line = line.rstrip()
            
            # æ£€æµ‹ä»£ç å¼€å§‹æ ‡å¿—
            if 'import ' in line:
                has_found_import = True
                in_code_section = True
            if '@Entry' in line:
                has_found_entry = True
                in_code_section = True
            if '@Component' in line:
                has_found_component = True
                in_code_section = True
            
            # è·³è¿‡æ˜æ˜¾çš„ä¸­æ–‡æ–‡æ¡£è¯´æ˜å’Œæ³¨é‡Š
            skip_patterns = [
                r'^æ ¹æ®.*',
                r'^ä»¥ä¸‹æ˜¯.*',
                r'^ä¸»è¦.*',
                r'^ä¿®å¤.*',
                r'^è¿™.*',
                r'^\d+\.',
                r'^[\u4e00-\u9fff]+[ï¼š:]',
                r'^```',
                r'^#',
                r'^>',
            ]
            
            should_skip = False
            for pattern in skip_patterns:
                if re.match(pattern, line):
                    should_skip = True
                    break
            
            if should_skip:
                continue
            
            # è·³è¿‡å«æœ‰å¤§é‡ä¸­æ–‡å­—ç¬¦çš„è¡Œï¼Œé™¤éæ˜¯åœ¨å­—ç¬¦ä¸²å­—é¢é‡ä¸­
            chinese_chars = re.findall(r'[\u4e00-\u9fff]', line)
            if len(chinese_chars) > 3 and not ("'" in line or '"' in line):
                continue
            
            # å¦‚æœæ˜¯ä»£ç è¡Œï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            if in_code_section or has_found_import or has_found_entry or has_found_component or line.strip().startswith("import "):
                # å¦‚æœæœ‰åŒ…å«ä¸­æ–‡çš„å­—ç¬¦ä¸²ï¼Œæ›¿æ¢ä¸ºè‹±æ–‡ç­‰æ•ˆå†…å®¹
                if "'" in line or '"' in line:
                    line = re.sub(r"'[^']*[\u4e00-\u9fff][^']*'", "'Text'", line)
                    line = re.sub(r'"[^"]*[\u4e00-\u9fff][^"]*"', '"Text"', line)
                
                # è·³è¿‡çº¯ä¸­æ–‡æ³¨é‡Šè¡Œ
                if line.strip().startswith("//") and re.search(r'[\u4e00-\u9fff]', line):
                    continue
                
                clean_lines.append(line)
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆä»£ç è¡Œï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        if not clean_lines:
            self.logger.warning("æ— æ³•æå–æœ‰æ•ˆä»£ç ")
            return ""
            
        return '\n'.join(clean_lines)
    
    def _clean_and_validate_code(self, code: str) -> str:
        """æ¸…ç†å’ŒéªŒè¯ä»£ç å†…å®¹"""
        import re
        
        lines = code.split('\n')
        clean_lines = []
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line:
                clean_lines.append('')
                continue
            
            # è·³è¿‡ä¸­æ–‡è§£é‡Šå’Œè¯´æ˜
            skip_patterns = [
                r'^æ ¹æ®.*',
                r'^ä»¥ä¸‹æ˜¯.*',
                r'^ä¸»è¦.*',
                r'^ä¿®å¤.*',
                r'^è¿™.*',
                r'^\d+\.',
                r'^[\u4e00-\u9fff]+ï¼š',
                r'^[\u4e00-\u9fff]+:',
                r'```'
            ]
            
            should_skip = False
            for pattern in skip_patterns:
                if re.match(pattern, line):
                    should_skip = True
                    break
            
            if should_skip:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼ˆé™¤äº†å­—ç¬¦ä¸²å­—é¢é‡ï¼‰
            if re.search(r'[\u4e00-\u9fff]', line):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²å­—é¢é‡ï¼Œä¿ç•™ä½†æ›¿æ¢ä¸­æ–‡ä¸ºè‹±æ–‡
                if "'" in line or '"' in line:
                    line = re.sub(r"'[^']*[\u4e00-\u9fff][^']*'", "'Text'", line)
                    line = re.sub(r'"[^"]*[\u4e00-\u9fff][^"]*"', '"Text"', line)
                    clean_lines.append(line)
                else:
                    # å…¶ä»–åŒ…å«ä¸­æ–‡çš„è¡Œè·³è¿‡
                    continue
            else:
                clean_lines.append(line)
        
        cleaned_code = '\n'.join(clean_lines)
        
        # éªŒè¯æ˜¯å¦åŒ…å«ArkTSåŸºæœ¬ç»“æ„
        if self._has_arkts_structure(cleaned_code):
            return cleaned_code
        
        return ""
    
    def _generate_basic_template(self) -> str:
        """ç”ŸæˆåŸºç¡€ArkTSæ¨¡æ¿"""
        return """import prompt from '@ohos.promptAction';

@Entry
@Component
struct Index {
  @State count: number = 0;

  build() {
    Column() {
      Text('Hello World')
        .fontSize(20)
        .fontWeight(FontWeight.Bold)
        .margin({ bottom: 20 })
      
      Button('Click Me')
        .width(150)
        .height(40)
        .onClick(() => {
          this.count++;
          prompt.showToast({
            message: `Count: ${this.count}`,
            duration: 2000
          });
        })
    }
    .width('100%')
    .height('100%')
    .justifyContent(FlexAlign.Center)
  }
}"""
    
    def _read_readme_content(self) -> str:
        """è¯»å–README.mdæ–‡ä»¶çš„å®é™…å†…å®¹"""
        try:
            readme_path = self.project_root / "MyApplication2" / "README.md"
            if readme_path.exists():
                with open(readme_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾è‡ªç„¶è¯­è¨€æè¿°éƒ¨åˆ†
                lines = content.split('\n')
                description_lines = []
                start_capturing = False
                
                for line in lines:
                    if "è‡ªç„¶è¯­è¨€æè¿°" in line:
                        start_capturing = True
                        continue
                    
                    if start_capturing:
                        # å¦‚æœé‡åˆ°æ–°çš„markdownæ ‡é¢˜ï¼Œåœæ­¢æ•è·ï¼ˆä½†å…è®¸ç¬¬ä¸‰çº§æ ‡é¢˜ï¼‰
                        if line.strip().startswith('##') and not line.strip().startswith('###'):
                            break
                        
                        # è·³è¿‡ç©ºè¡Œå’Œmarkdownè¯­æ³•ï¼Œä½†ä¿ç•™å†…å®¹
                        if line.strip() and not line.strip().startswith('---'):
                            description_lines.append(line.strip())
                
                description = '\n'.join(description_lines)
                self.logger.info(f"ä»£ç ç”ŸæˆAgentè¯»å–README.mdæè¿°: {len(description)} å­—ç¬¦")
                
                return description if description else content
            else:
                self.logger.warning("README.mdæ–‡ä»¶ä¸å­˜åœ¨")
                return ""
                
        except Exception as e:
            self.logger.error(f"è¯»å–README.mdå¤±è´¥: {e}")
            return ""
    
    def _extract_optimization_notes(self, response: str) -> List[str]:
        """ä»ä¼˜åŒ–å“åº”ä¸­æå–ä¼˜åŒ–è¯´æ˜"""
        response = BaseLLM.remove_think(response)
        
        # ç®€å•çš„ä¼˜åŒ–è¯´æ˜æå–
        lines = response.split('\n')
        notes = []
        
        for line in lines:
            line = line.strip()
            if line.startswith('- ') or line.startswith('* ') or line.startswith('1. '):
                notes.append(line)
        
        return notes[:10]  # æœ€å¤šè¿”å›10ä¸ªä¼˜åŒ–ç‚¹
    
    def _generate_usage_instructions(self, template_type: str, language: str) -> str:
        """ç”Ÿæˆæ¨¡æ¿ä½¿ç”¨è¯´æ˜"""
        return f"""
ä½¿ç”¨è¯´æ˜ï¼š
1. è¿™æ˜¯ä¸€ä¸ª{language} {template_type}æ¨¡æ¿
2. è¯·æ ¹æ®å®é™…éœ€æ±‚å¡«å†™TODOæ ‡è®°çš„éƒ¨åˆ†
3. æ ¹æ®é¡¹ç›®éœ€è¦è°ƒæ•´å¯¼å…¥å’Œä¾èµ–
4. è¿è¡Œå‰è¯·ç¡®ä¿ç¯å¢ƒé…ç½®æ­£ç¡®
5. å»ºè®®è¿›è¡Œå•å…ƒæµ‹è¯•éªŒè¯åŠŸèƒ½
"""
    
    async def get_prompts(self) -> List[Dict[str, Any]]:
        """è·å–æ”¯æŒçš„Prompts"""
        return [
            {
                "name": "generate_code",
                "description": "æ ¹æ®éœ€æ±‚ç”Ÿæˆä»£ç ",
                "arguments": [
                    {
                        "name": "requirement",
                        "description": "ä»£ç éœ€æ±‚æè¿°",
                        "required": True
                    },
                    {
                        "name": "language",
                        "description": "ç¼–ç¨‹è¯­è¨€",
                        "required": True
                    },
                    {
                        "name": "context",
                        "description": "ä¸Šä¸‹æ–‡ä¿¡æ¯",
                        "required": False
                    }
                ]
            },
            {
                "name": "generate_template",
                "description": "ç”Ÿæˆä»£ç æ¨¡æ¿",
                "arguments": [
                    {
                        "name": "template_type",
                        "description": "æ¨¡æ¿ç±»å‹",
                        "required": True
                    },
                    {
                        "name": "language",
                        "description": "ç¼–ç¨‹è¯­è¨€",
                        "required": True
                    }
                ]
            }
        ]
    
    async def get_tools(self) -> List[Dict[str, Any]]:
        """è·å–æ”¯æŒçš„Tools"""
        return [
            {
                "name": "code_generate",
                "description": "æ ¹æ®éœ€æ±‚å’Œä¸Šä¸‹æ–‡ç”Ÿæˆä»£ç ",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "requirement": {
                            "type": "string",
                            "description": "ä»£ç éœ€æ±‚æè¿°"
                        },
                        "language": {
                            "type": "string",
                            "description": "ç¼–ç¨‹è¯­è¨€",
                            "enum": ["python", "javascript", "typescript", "arkts", "cpp", "java", "go"]
                        },
                        "context": {
                            "type": "string",
                            "description": "ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæœç´¢ç»“æœã€æ–‡æ¡£ç­‰ï¼‰"
                        },
                        "framework": {
                            "type": "string",
                            "description": "ä½¿ç”¨çš„æ¡†æ¶æˆ–åº“"
                        }
                    },
                    "required": ["requirement", "language"]
                }
            },
            {
                "name": "code_template",
                "description": "ç”Ÿæˆä»£ç æ¨¡æ¿",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "template_type": {
                            "type": "string",
                            "description": "æ¨¡æ¿ç±»å‹ï¼ˆå¦‚ï¼šclass, function, api, web_appç­‰ï¼‰"
                        },
                        "language": {
                            "type": "string",
                            "description": "ç¼–ç¨‹è¯­è¨€"
                        },
                        "parameters": {
                            "type": "object",
                            "description": "æ¨¡æ¿å‚æ•°"
                        }
                    },
                    "required": ["template_type", "language"]
                }
            }
        ]
    
    # ==================== é¸¿è’™ä¸“ç”¨æ–¹æ³• ====================
    
    async def _generate_harmonyos_code(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆé¸¿è’™ArkTSä»£ç  - æ”¯æŒä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ä»»åŠ¡å¤„ç†"""
        try:
            # ä»æ–°çš„ä¸Šä¸‹æ–‡ç³»ç»Ÿè·å–å‚æ•°
            user_requirement = params.get("user_requirement", params.get("requirement", ""))
            current_task_type = params.get("current_task_type", "initial_generation")
            current_phase = params.get("current_phase", "code_generation")
            fix_attempt = params.get("fix_attempt", 0)
            
            self.logger.info(f"ä»£ç ç”ŸæˆAgentæ”¶åˆ°ä»»åŠ¡")
            self.logger.info(f"å½“å‰é˜¶æ®µ: {current_phase}")
            self.logger.info(f"ä»»åŠ¡ç±»å‹: {current_task_type}")
            self.logger.info(f"ä¿®å¤å°è¯•: {fix_attempt}")
            self.logger.info(f"ç”¨æˆ·éœ€æ±‚: {user_requirement}")
            
            if not user_requirement:
                raise ValueError("éœ€æ±‚æè¿°ä¸èƒ½ä¸ºç©º")
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
            if current_task_type == "error_fixing":
                result = await self._handle_error_fixing(params)
            else:
                result = await self._handle_initial_generation(params)
            
            self.logger.info(f"ä»£ç ç”Ÿæˆå®Œæˆ: {result.get('success', False)}")
            return result
                
        except Exception as e:
            self.logger.error(f"é¸¿è’™ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "generated_files": [],
                "task_type": current_task_type
            }
    
    def _build_harmonyos_prompt(self, is_fixing: bool = False, previous_errors: List = None) -> str:
        """æ„å»ºé¸¿è’™ä»£ç ç”Ÿæˆæç¤ºè¯"""
        base_prompt = """Generate HarmonyOS ArkTS code. Use @Entry @Component decorators, proper struct and build() method, appropriate state management."""

        if is_fixing and previous_errors:
            fix_prompt = f"""
Fix these errors:
{previous_errors}
Focus on imports, decorators, syntax, and types.
"""
            return base_prompt + fix_prompt
        
        return base_prompt
    
    async def _process_and_save_code(self, generated_content: str, target_files: List[Dict], project_path: str) -> List[Dict[str, Any]]:
        """å¤„ç†ç”Ÿæˆçš„ä»£ç å¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
        import re
        import os
        
        generated_files = []
        
        try:
            # å°è¯•ä»LLMå“åº”ä¸­æå–æ–‡ä»¶ä»£ç 
            if "```" in generated_content:
                # æå–ä»£ç å—
                code_blocks = re.findall(r'```(?:arkts|typescript|ets)?\n(.*?)\n```', generated_content, re.DOTALL)
                
                for i, target_file in enumerate(target_files):
                    file_path = target_file["path"]
                    file_type = target_file["type"]
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    
                    # è·å–ä»£ç å†…å®¹
                    if i < len(code_blocks):
                        code_content = code_blocks[i].strip()
                    else:
                        # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ä»£ç å—ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                        code_content = self._generate_fallback_code(file_type, file_path)
                    
                    # ä¿å­˜æ–‡ä»¶
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(code_content)
                    
                    generated_files.append({
                        "path": file_path,
                        "type": file_type,
                        "size": len(code_content),
                        "content_preview": code_content[:200] + "..." if len(code_content) > 200 else code_content
                    })
                    
                    self.logger.info(f"å·²ç”Ÿæˆæ–‡ä»¶: {file_path}")
            
            else:
                # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•ä»æ•´ä¸ªå“åº”ä¸­æå–ä»£ç æˆ–ç”Ÿæˆå¤‡ç”¨ä»£ç 
                for target_file in target_files:
                    file_path = target_file["path"]
                    file_type = target_file["type"]
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    
                    # å°è¯•æå–çº¯ä»£ç å†…å®¹
                    code_content = self._extract_pure_code(generated_content, file_type, file_path)
                    
                    # ä¿å­˜æ–‡ä»¶
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(code_content)
                    
                    generated_files.append({
                        "path": file_path,
                        "type": file_type,
                        "size": len(code_content),
                        "content_preview": code_content[:200] + "..." if len(code_content) > 200 else code_content
                    })
                    
                    self.logger.info(f"å·²ç”Ÿæˆæ¨¡æ¿æ–‡ä»¶: {file_path}")
            
            return generated_files
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä»£ç æ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def _generate_fallback_code(self, file_type: str, file_path: str) -> str:
        """ç¦ç”¨ç¡¬ç¼–ç å¤‡ç”¨æ¨¡æ¿ - å¼ºåˆ¶ä½¿ç”¨LLMç”Ÿæˆ"""
        self.logger.error(f"âŒ è¯•å›¾ä½¿ç”¨ç¡¬ç¼–ç å¤‡ç”¨æ¨¡æ¿ï¼Œè¿™å·²è¢«ç¦ç”¨: {file_path}")
        self.logger.error(f"âŒ å¿…é¡»ä½¿ç”¨LLMç”Ÿæˆä»£ç ï¼Œä¸å…è®¸ç¡¬ç¼–ç æ¨¡æ¿")
        raise ValueError(f"ç¡¬ç¼–ç å¤‡ç”¨æ¨¡æ¿å·²è¢«ç¦ç”¨ï¼Œå¿…é¡»ä½¿ç”¨LLMç”Ÿæˆä»£ç : {file_path}")
    
    def _extract_pure_code(self, generated_content: str, file_type: str, file_path: str) -> str:
        """ä»LLMå“åº”ä¸­æå–çº¯ä»£ç å†…å®¹"""
        import re
        
        # å°è¯•å¤šç§æ–¹å¼æå–ä»£ç 
        
        # 1. é¦–å…ˆå°è¯•æå–ä»£ç å—ï¼ˆæ›´å®½æ¾çš„æ­£åˆ™ï¼‰
        code_block_patterns = [
            r'```(?:arkts|typescript|ets|ts)?\s*\n(.*?)\n```',
            r'```\s*\n(.*?)\n```',
            r'```(.*?)```'
        ]
        
        for pattern in code_block_patterns:
            matches = re.findall(pattern, generated_content, re.DOTALL)
            if matches:
                code = matches[0].strip()
                # ç›´æ¥æ¸…ç†ä¸­æ–‡å†…å®¹ï¼Œä¸ä¾èµ–éªŒè¯
                cleaned_code = self._remove_chinese_from_code(code)
                if self._has_arkts_structure(cleaned_code):
                    return cleaned_code
        
        # 2. å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ArkTSç»“æ„
        lines = generated_content.split('\n')
        code_lines = []
        in_code_section = False
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡æ˜æ˜¾çš„ä¸­æ–‡æ–‡æ¡£è¯´æ˜å’Œè§£é‡Š
            skip_keywords = ['ä¸»è¦ä¿®å¤å†…å®¹', 'ä¿®å¤è¯´æ˜', 'ä»¥ä¸‹æ˜¯', 'æ ¹æ®', 'è¿™äº›ä¿®æ”¹', 'ä¿®å¤ç‚¹', 'ä¿®å¤äº†', 'ä¿®æ­£äº†', 'ä¼˜åŒ–äº†', 'åº”è¯¥èƒ½è§£å†³', 'ä¸»è¦ä¿®å¤ç‚¹', 'è¿™äº›ä¿®æ”¹åº”è¯¥èƒ½è§£å†³']
            if any(keyword in line for keyword in skip_keywords):
                continue
            
            # è·³è¿‡çº¯ä¸­æ–‡è¡Œå’Œæ•°å­—ç¼–å·è¡Œ
            if re.match(r'^\d+\.', line) or re.match(r'^[\u4e00-\u9fff]+ï¼š', line):
                continue
            
            # è·³è¿‡markdownæ ‡è®°è¡Œ
            if line.startswith('```') or line.strip() == '```':
                continue
            
            # æ£€æµ‹ä»£ç å¼€å§‹
            if any(keyword in line for keyword in ['import ', '@Entry', '@Component', 'struct ', 'class ']):
                in_code_section = True
            
            # å¦‚æœåœ¨ä»£ç åŒºåŸŸï¼Œæ”¶é›†ä»£ç è¡Œ
            if in_code_section:
                # åªæ¥å—è‹±æ–‡æ³¨é‡Šå’Œä»£ç è¡Œï¼Œè·³è¿‡ä¸­æ–‡æ³¨é‡Šå’Œè§£é‡Š
                if line and (not line.startswith('//') or (line.startswith('//') and not re.search(r'[\u4e00-\u9fff]', line))):
                    # è¿›ä¸€æ­¥è¿‡æ»¤åŒ…å«ä¸­æ–‡å­—ç¬¦çš„è¡Œï¼ˆé™¤äº†å­—ç¬¦ä¸²å­—é¢é‡ï¼‰
                    if not re.search(r'[\u4e00-\u9fff]', line) or "'" in line or '"' in line:
                        code_lines.append(line)
        
        if code_lines:
            extracted_code = '\n'.join(code_lines)
            if self._is_valid_arkts_code(extracted_code):
                return extracted_code
        
        # 3. æœ€åå¤‡ç”¨æ–¹æ¡ˆ - ä¸ä½¿ç”¨ç¡¬ç¼–ç æ¨¡æ¿
        self.logger.warning(f"âš ï¸ æ— æ³•ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆä»£ç : {file_path}")
        self.logger.warning(f"âš ï¸ LLMå“åº”å†…å®¹: {generated_content[:500]}...")
        raise ValueError(f"æ— æ³•ä»LLMå“åº”ä¸­æå–æœ‰æ•ˆçš„ArkTSä»£ç : {file_path}")
    
    def _is_valid_arkts_code(self, code: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ArkTSä»£ç """
        import re
        
        # åŸºæœ¬çš„ArkTSä»£ç ç‰¹å¾æ£€æŸ¥
        arkts_keywords = ['@Entry', '@Component', 'struct', 'build()', 'import']
        has_arkts_structure = any(keyword in code for keyword in arkts_keywords)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡å¤šçš„ä¸­æ–‡æ–‡æ¡£è¯´æ˜
        doc_keywords = ['ä¸»è¦ä¿®å¤', 'ä¿®å¤è¯´æ˜', 'ä»¥ä¸‹æ˜¯', 'è¿™äº›ä¿®æ”¹è§£å†³äº†', 'ä¿®å¤ç‚¹', 'ä¿®å¤äº†', 'ä¿®æ­£äº†', 'ä¼˜åŒ–äº†', 'åº”è¯¥èƒ½è§£å†³']
        has_too_much_doc = any(keyword in code for keyword in doc_keywords)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡æ³¨é‡Šæˆ–ä¸­æ–‡å­—ç¬¦åœ¨ä¸»è¦ä»£ç åŒºåŸŸ
        chinese_in_code = re.search(r'[\u4e00-\u9fff]', code)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«markdownæ ‡è®°
        has_markdown = '```' in code
        
        return has_arkts_structure and not has_too_much_doc and not chinese_in_code and not has_markdown
    
    def _has_arkts_structure(self, code: str) -> bool:
        """æ£€æŸ¥ä»£ç æ˜¯å¦å…·æœ‰ArkTSç»“æ„"""
        arkts_keywords = ['@Entry', '@Component', 'struct', 'build()', 'import']
        return any(keyword in code for keyword in arkts_keywords)
    
    def _remove_chinese_from_code(self, code: str) -> str:
        """ä»ä»£ç ä¸­ç§»é™¤ä¸­æ–‡å­—ç¬¦å’Œè§£é‡Šæ–‡å­—"""
        import re
        lines = code.split('\n')
        clean_lines = []
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡æ˜æ˜¾çš„ä¸­æ–‡æ–‡æ¡£è¯´æ˜
            skip_keywords = ['ä¸»è¦ä¿®å¤å†…å®¹', 'ä¿®å¤è¯´æ˜', 'ä»¥ä¸‹æ˜¯', 'æ ¹æ®', 'è¿™äº›ä¿®æ”¹', 'ä¿®å¤ç‚¹', 'ä¿®å¤äº†', 'ä¿®æ­£äº†', 'ä¼˜åŒ–äº†', 'åº”è¯¥èƒ½è§£å†³', 'ä¸»è¦ä¿®å¤ç‚¹', 'è¿™äº›ä¿®æ”¹åº”è¯¥èƒ½è§£å†³']
            if any(keyword in line for keyword in skip_keywords):
                continue
            
            # è·³è¿‡çº¯ä¸­æ–‡è¡Œå’Œæ•°å­—ç¼–å·è¡Œ
            if re.match(r'^\d+\.', line) or re.match(r'^[\u4e00-\u9fff]+ï¼š', line):
                continue
            
            # è·³è¿‡markdownæ ‡è®°è¡Œ
            if line.startswith('```') or line.strip() == '```':
                continue
            
            # å¤„ç†åŒ…å«ä¸­æ–‡çš„ä»£ç è¡Œ
            if re.search(r'[\u4e00-\u9fff]', line):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²å­—é¢é‡ï¼Œæ›¿æ¢ä¸ºè‹±æ–‡
                if "'" in line or '"' in line:
                    # æ›¿æ¢ä¸­æ–‡å­—ç¬¦ä¸²ä¸ºè‹±æ–‡
                    line = re.sub(r"'[^']*[\u4e00-\u9fff][^']*'", "'Chinese text'", line)
                    line = re.sub(r'"[^"]*[\u4e00-\u9fff][^"]*"', '"Chinese text"', line)
                    clean_lines.append(line)
                # å¦‚æœæ˜¯ä¸­æ–‡æ³¨é‡Šï¼Œè·³è¿‡
                elif line.startswith('//'):
                    continue
                # å…¶ä»–åŒ…å«ä¸­æ–‡çš„è¡Œï¼Œè·³è¿‡
                else:
                    continue
            else:
                clean_lines.append(line)
        
        cleaned_code = '\n'.join(clean_lines)
        
        # æœ€åä¸€æ¬¡æ¸…ç†ï¼Œç¡®ä¿æ²¡æœ‰ä¸­æ–‡å­—ç¬¦
        if re.search(r'[\u4e00-\u9fff]', cleaned_code):
            # å¦‚æœä»æœ‰ä¸­æ–‡ï¼Œåšæœ€åçš„æ¸…ç†
            final_lines = []
            for line in cleaned_code.split('\n'):
                if not re.search(r'[\u4e00-\u9fff]', line):
                    final_lines.append(line)
            cleaned_code = '\n'.join(final_lines)
        
        return cleaned_code
    
    # ==================== ç®€åŒ–çš„ä»£ç ç”Ÿæˆæ–¹æ³• ====================
    
    def simple_generate_code(self, user_requirements: str, search_results: str = "") -> str:
        """ç®€åŒ–çš„ä»£ç ç”Ÿæˆæ–¹æ³•"""
        try:
            from .simple_prompts import INITIAL_CODE_GENERATION_PROMPT
            
            prompt = INITIAL_CODE_GENERATION_PROMPT.format(
                user_requirements=user_requirements,
                search_results=search_results or "No search results available"
            )
            
            messages = [{"role": "user", "content": prompt}]
            response = self.llm_client.chat(messages)
            
            # ç®€å•çš„ä»£ç æå–
            code = response.content.strip()
            
            # ç§»é™¤markdownæ ‡è®°
            if code.startswith('```'):
                lines = code.split('\n')
                code = '\n'.join(lines[1:-1])
            
            # ç§»é™¤ä¸­æ–‡è¡Œ
            lines = code.split('\n')
            clean_lines = []
            for line in lines:
                if not self._contains_chinese(line) or "'" in line or '"' in line:
                    clean_lines.append(line)
            
            return '\n'.join(clean_lines)
            
        except Exception as e:
            self.logger.error(f"ç®€åŒ–ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            # ä¸ä½¿ç”¨ç¡¬ç¼–ç æ¨¡æ¿ï¼ŒæŠ›å‡ºé”™è¯¯è®©è°ƒç”¨è€…å¤„ç†
            raise
    
    def simple_fix_code(self, user_requirements: str, original_code: str, error_info: str, search_results: str = "") -> str:
        """ç®€åŒ–çš„ä»£ç ä¿®å¤æ–¹æ³•"""
        try:
            from .simple_prompts import ERROR_FIXING_PROMPT
            
            prompt = ERROR_FIXING_PROMPT.format(
                user_requirements=user_requirements,
                original_code=original_code,
                error_info=error_info,
                search_results=search_results or "No search results available"
            )
            
            messages = [{"role": "user", "content": prompt}]
            response = self.llm_client.chat(messages)
            
            # ç®€å•çš„ä»£ç æå–
            code = response.content.strip()
            
            # ç§»é™¤markdownæ ‡è®°
            if code.startswith('```'):
                lines = code.split('\n')
                code = '\n'.join(lines[1:-1])
            
            # ç§»é™¤ä¸­æ–‡è¡Œ
            lines = code.split('\n')
            clean_lines = []
            for line in lines:
                if not self._contains_chinese(line) or "'" in line or '"' in line:
                    clean_lines.append(line)
            
            return '\n'.join(clean_lines)
            
        except Exception as e:
            self.logger.error(f"ç®€åŒ–ä»£ç ä¿®å¤å¤±è´¥: {e}")
            return original_code
    
    def _contains_chinese(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        import re
        return bool(re.search(r'[\u4e00-\u9fff]', text))
    
    def _simple_extract_code(self, response: str) -> str:
        """ç®€åŒ–çš„ä»£ç æå–æ–¹æ³• - æœ€å°ç¨‹åº¦æ¸…ç†ï¼Œä¿ç•™LLMåŸå§‹è¾“å‡º"""
        import re
        
        # ç§»é™¤æ€è€ƒæ ‡ç­¾
        response = BaseLLM.remove_think(response)
        
        # 1. é¦–å…ˆå°è¯•æå–markdownä»£ç å—
        code_patterns = [
            r'```(?:arkts|typescript|ets|ts)?\s*\n(.*?)\n```',
            r'```\s*\n(.*?)\n```',
            r'```(.*?)```'
        ]
        
        for pattern in code_patterns:
            matches = re.findall(pattern, response, re.DOTALL)
            if matches:
                code = matches[0].strip()
                self.logger.info(f"ğŸ” ä»ä»£ç å—ä¸­æå–åˆ°ä»£ç ï¼Œé•¿åº¦: {len(code)}")
                return code
        
        # 2. å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œæ£€æŸ¥æ˜¯å¦æ•´ä¸ªå“åº”å°±æ˜¯ä»£ç 
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ArkTSç‰¹å¾
        if any(keyword in response for keyword in ['@Entry', '@Component', 'struct', 'build()', 'import']):
            self.logger.info(f"ğŸ” æ£€æµ‹åˆ°ArkTSå…³é”®è¯ï¼Œä½¿ç”¨æ•´ä¸ªå“åº”ä½œä¸ºä»£ç ")
            return response.strip()
        
        # 3. å°è¯•æŸ¥æ‰¾çº¯ä»£ç æ®µï¼ˆä»importæˆ–@Entryå¼€å§‹ï¼‰
        lines = response.split('\n')
        code_start = -1
        
        for i, line in enumerate(lines):
            line = line.strip()
            if any(keyword in line for keyword in ['import ', '@Entry', '@Component', 'struct ']):
                code_start = i
                break
        
        if code_start >= 0:
            code_lines = lines[code_start:]
            code = '\n'.join(code_lines).strip()
            self.logger.info(f"ğŸ” ä»ç¬¬{code_start}è¡Œå¼€å§‹æå–ä»£ç ï¼Œé•¿åº¦: {len(code)}")
            return code
        
        # 4. æœ€åå¤‡ç”¨ï¼šä½¿ç”¨åŸå§‹å“åº”
        self.logger.warning(f"âš ï¸ æ— æ³•è¯†åˆ«ä»£ç ç»“æ„ï¼Œä½¿ç”¨åŸå§‹å“åº”")
        return response.strip()

    # ==================== ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»»åŠ¡å¤„ç†æ–¹æ³• ====================
    
    async def _handle_initial_generation(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†åˆå§‹ä»£ç ç”Ÿæˆä»»åŠ¡"""
        try:
            self.logger.info("å¼€å§‹åˆå§‹ä»£ç ç”Ÿæˆ")
            
            # ä»é¡¹ç›®è§„åˆ’å’Œå‚è€ƒèµ„æ–™ä¸­è·å–ä¿¡æ¯
            project_plan = params.get("project_plan", {})
            planned_files = params.get("planned_files", [])
            reference_materials = params.get("reference_materials", [])
            
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = self._build_generation_context(project_plan, reference_materials)
            
            # ä¸ºæ¯ä¸ªè®¡åˆ’æ–‡ä»¶ç”Ÿæˆä»£ç 
            generated_files = []
            for file_plan in planned_files:
                file_content = await self._generate_file_content(file_plan, context_info)
                
                if file_content:
                    # ä¿å­˜æ–‡ä»¶
                    file_path = file_plan.get("path", "")
                    if file_path:
                        await self._save_file_content(file_path, file_content)
                        generated_files.append({
                            "path": file_path,
                            "type": file_plan.get("type", "arkts"),
                            "content": file_content,
                            "status": "generated"
                        })
            
            self.logger.info(f"åˆå§‹ä»£ç ç”Ÿæˆå®Œæˆ: {len(generated_files)} ä¸ªæ–‡ä»¶")
            
            return {
                "success": True,
                "generated_files": generated_files,
                "task_type": "initial_generation",
                "total_files": len(generated_files)
            }
            
        except Exception as e:
            self.logger.error(f"åˆå§‹ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "generated_files": [],
                "task_type": "initial_generation"
            }
    
    async def _handle_error_fixing(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é”™è¯¯ä¿®å¤ä»»åŠ¡"""
        try:
            self.logger.info("å¼€å§‹é”™è¯¯ä¿®å¤")
            
            # ç¡®ä¿è·å–å®Œæ•´çš„ç”¨æˆ·éœ€æ±‚ï¼ˆåŒ…æ‹¬READMEå†…å®¹ï¼‰
            user_requirement = params.get("user_requirement", params.get("requirement", ""))
            
            # ä»MyApplication2/README.mdè¯»å–å®Œæ•´çš„éœ€æ±‚æè¿°
            readme_content = self._read_readme_requirement()
            if readme_content:
                user_requirement = readme_content
                self.logger.info(f"ä»README.mdè¯»å–åˆ°å®Œæ•´éœ€æ±‚: {len(user_requirement)} å­—ç¬¦")
            
            # ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ç®¡ç†Agentçš„ç²¾ç¡®åˆ†æç»“æœ
            error_analysis = params.get("error_analysis", [])
            files_to_fix = params.get("files_to_fix", [])
            target_files_with_locations = params.get("target_files_with_locations", [])
            precise_targeting = params.get("precise_targeting", False)
            
            # å¤‡ç”¨ï¼šåŸå§‹é”™è¯¯ä¿¡æ¯
            errors_to_fix = params.get("errors_to_fix", [])
            solution_references = params.get("solution_references", [])
            existing_files = params.get("existing_files", [])
            
            self.logger.info(f"ğŸ“ ä½¿ç”¨ç²¾ç¡®å®šä½: {precise_targeting}")
            self.logger.info(f"ğŸ“ é¡¹ç›®ç®¡ç†Agentåˆ†æ: {len(error_analysis)} ä¸ªé”™è¯¯")
            self.logger.info(f"ğŸ“ ç¡®å®šä¿®å¤æ–‡ä»¶: {len(files_to_fix)} ä¸ªæ–‡ä»¶")
            self.logger.info(f"ğŸ“ åŸå§‹é”™è¯¯ä¿¡æ¯: {len(errors_to_fix)} ä¸ª")
            self.logger.info(f"ğŸ“ ç°æœ‰æ–‡ä»¶: {len(existing_files)} ä¸ª")
            
            # ä½¿ç”¨å¢å¼ºçš„é”™è¯¯è¿‡æ»¤å™¨
            from shared.error_analysis import workflow_error_filter
            
            # è·å–åŸå§‹è¾“å‡ºç”¨äºç»Ÿè®¡åˆ†æ
            raw_outputs = []
            for error in errors_to_fix:
                if error.get('raw_output'):
                    raw_outputs.append(error.get('raw_output'))
                elif error.get('raw_message'):
                    raw_outputs.append(error.get('raw_message'))
            
            combined_output = '\n'.join(raw_outputs)
            
            # è®°å½•åŸå§‹é”™è¯¯æ•°é‡ç”¨äºéªŒè¯
            original_error_count = len(errors_to_fix)
            self.logger.info(f"ğŸ” å¼€å§‹æ™ºèƒ½é”™è¯¯è¿‡æ»¤ï¼ŒåŸå§‹é”™è¯¯æ•°: {original_error_count}")
            
            # ä½¿ç”¨å¢å¼ºè¿‡æ»¤å™¨æ£€æŸ¥çœŸå®é”™è¯¯
            filtered_real_errors = workflow_error_filter.filter_errors_for_workflow(errors_to_fix, combined_output)
            
            self.logger.info(f"ğŸ” æ™ºèƒ½è¿‡æ»¤åé”™è¯¯æ•°: {len(filtered_real_errors)}")
            
            # å¦‚æœè¿‡æ»¤å™¨ç§»é™¤äº†æ‰€æœ‰é”™è¯¯ï¼Œä½†åŸæœ¬æœ‰é”™è¯¯ï¼Œå¯èƒ½å­˜åœ¨è¯¯åˆ¤
            if not filtered_real_errors and original_error_count > 0:
                self.logger.warning(f"âš ï¸ æ™ºèƒ½è¿‡æ»¤ç§»é™¤äº†æ‰€æœ‰{original_error_count}ä¸ªé”™è¯¯ï¼Œå¯èƒ½å­˜åœ¨è¯¯åˆ¤")
                self.logger.warning("âš ï¸ ä¿ç•™åŸå§‹é”™è¯¯è¿›è¡Œä¿®å¤å°è¯•ï¼Œé¿å…é—æ¼çœŸå®é—®é¢˜")
                
                # è‡³å°‘ä¿ç•™å‰3ä¸ªé”™è¯¯è¿›è¡Œä¿®å¤å°è¯•
                errors_to_fix = errors_to_fix[:3]
                self.logger.info(f"ğŸ”„ å›é€€ç­–ç•¥ï¼šä¿ç•™å‰{len(errors_to_fix)}ä¸ªåŸå§‹é”™è¯¯è¿›è¡Œä¿®å¤")
            else:
                # ä½¿ç”¨è¿‡æ»¤åçš„ç»“æœ
                errors_to_fix = filtered_real_errors
            self.logger.info(f"æ™ºèƒ½è¿‡æ»¤åçš„çœŸå®é”™è¯¯æ•°é‡: {len(errors_to_fix)}")
            
            if not errors_to_fix and not error_analysis:
                self.logger.warning("æ²¡æœ‰é”™è¯¯éœ€è¦ä¿®å¤")
                return {
                    "success": True,
                    "fixed_files": [],
                    "task_type": "error_fixing",
                    "message": "æ²¡æœ‰é”™è¯¯éœ€è¦ä¿®å¤"
                }
            
            # æŒ‰æ–‡ä»¶åˆ†ç»„é”™è¯¯ - ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ç®¡ç†Agentçš„ç²¾ç¡®åˆ†æ
            errors_by_file = {}
            
            if precise_targeting and error_analysis:
                # ä½¿ç”¨é¡¹ç›®ç®¡ç†Agentçš„ç²¾ç¡®åˆ†æç»“æœ
                self.logger.info(f"ğŸ” ä½¿ç”¨é¡¹ç›®ç®¡ç†Agentçš„ç²¾ç¡®åˆ†æ: {len(error_analysis)} ä¸ªé”™è¯¯")
                
                for analysis in error_analysis:
                    target_file = analysis.get("target_file", "")
                    error_id = analysis.get("error_id", 0)
                    fix_description = analysis.get("fix_description", "")
                    fix_location = analysis.get("location", "")
                    
                    self.logger.info(f"   é”™è¯¯{error_id}: target_file='{target_file}', location='{fix_location}'")
                    
                    if target_file and target_file.startswith("MyApplication2/"):
                        if target_file not in errors_by_file:
                            errors_by_file[target_file] = []
                        
                        # åˆ›å»ºå¢å¼ºçš„é”™è¯¯å¯¹è±¡
                        enhanced_error = {
                            "error_id": error_id,
                            "message": analysis.get("error_message", ""),
                            "file_path": target_file,
                            "fix_description": fix_description,
                            "fix_location": fix_location,
                            "root_cause": analysis.get("root_cause", ""),
                            "search_keywords": analysis.get("search_keywords", []),
                            "from_analysis": True,  # æ ‡è®°æ¥æºäºé¡¹ç›®ç®¡ç†Agentåˆ†æ
                            "severity": "error"  # æ˜ç¡®è®¾ç½®ä¸ºé”™è¯¯çº§åˆ«
                        }
                        errors_by_file[target_file].append(enhanced_error)
                    
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨è¿‡æ»¤åçš„åŸå§‹é”™è¯¯ä¿¡æ¯
                self.logger.info(f"ğŸ” ä½¿ç”¨åŸå§‹é”™è¯¯ä¿¡æ¯: {len(errors_to_fix)} ä¸ªé”™è¯¯")
                
                for i, error in enumerate(errors_to_fix):
                    file_path = error.get("file_path", "")
                    error_message = error.get("message", "Unknown error")
                    
                    self.logger.info(f"   é”™è¯¯{i+1}: file_path='{file_path}', message='{error_message[:100]}'")
                    
                    # å¤„ç†æ–‡ä»¶è·¯å¾„é—®é¢˜
                    if not file_path or file_path in ["unknown", "", " "]:
                        # å¯¹äºæ— æ³•ç¡®å®šæ–‡ä»¶çš„é”™è¯¯ï¼Œå°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æ¨æ–­
                        if "Resource Pack Error" in error_message or "string.json" in error_message or "base/element" in error_message:
                            # èµ„æºé”™è¯¯é€šå¸¸æ¶‰åŠèµ„æºæ–‡ä»¶
                            file_path = "MyApplication2/entry/src/main/resources/base/element/string.json"
                        elif "module.json" in error_message or "module.json5" in error_message:
                            # module.jsonç›¸å…³é”™è¯¯
                            file_path = "MyApplication2/entry/src/main/module.json5"
                        elif "build" in error_message or "compilation" in error_message:
                            # ç¼–è¯‘é”™è¯¯ï¼Œä»ç°æœ‰æ–‡ä»¶ä¸­æ‰¾åˆ°ç¬¬ä¸€ä¸ª.etsæ–‡ä»¶
                            first_ets_file = None
                            for existing_file in existing_files:
                                if existing_file.get("path", "").endswith(".ets"):
                                    first_ets_file = existing_file.get("path")
                                    break
                            file_path = first_ets_file or "MyApplication2/entry/src/main/ets/pages/Index.ets"
                        else:
                            # é»˜è®¤ä½¿ç”¨Index.ets
                            file_path = "MyApplication2/entry/src/main/ets/pages/Index.ets"
                        self.logger.info(f"     -> æ¨æ–­æ–‡ä»¶è·¯å¾„: {file_path}")
                    
                    # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ˜¯Index.tsï¼Œç¡®ä¿ä¿®æ”¹ä¸ºIndex.ets
                    if file_path.endswith("Index.ts"):
                        old_path = file_path
                        file_path = file_path.replace("Index.ts", "Index.ets")
                        self.logger.info(f"å°†æ–‡ä»¶è·¯å¾„ä» {old_path} æ›´æ­£ä¸º {file_path}")
                    
                    if file_path not in errors_by_file:
                        errors_by_file[file_path] = []
                    errors_by_file[file_path].append(error)
            
            self.logger.info(f"ğŸ“‹ é”™è¯¯åˆ†ç»„å®Œæˆ: {len(errors_by_file)} ä¸ªæ–‡ä»¶")
            
            # ä¿®å¤æ¯ä¸ªæ–‡ä»¶çš„é”™è¯¯
            fixed_files = []
            
            for j, (file_path, file_errors) in enumerate(errors_by_file.items()):
                self.logger.info(f"=== ä¿®å¤æ–‡ä»¶ {j+1}/{len(errors_by_file)}: {file_path} ===")
                self.logger.info(f"  æ–‡ä»¶é”™è¯¯æ•°é‡: {len(file_errors)} ä¸ª")
                
                # è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹ï¼ˆåˆå§‹ä»£ç ï¼‰
                import os
                existing_content = ""
                if os.path.exists(file_path):
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            existing_content = f.read()
                    except Exception as e:
                        self.logger.warning(f"è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
                
                # ä½¿ç”¨æ–°çš„å·¥ä½œæµç‰¹å®šçš„ä¿®å¤æ–¹æ³•ï¼Œç¡®ä¿ä¼ é€’å®Œæ•´ä¿¡æ¯ï¼šç”¨æˆ·éœ€æ±‚ã€é”™è¯¯ä¿¡æ¯ã€åˆå§‹ä»£ç 
                fixed_content = await self._fix_file_errors_with_prompt(
                    file_path, 
                    file_errors, 
                    existing_files, 
                    solution_references,
                    workflow_type="error_fixing",
                    user_requirement=user_requirement,  # ä¼ é€’å®Œæ•´ç”¨æˆ·éœ€æ±‚
                    existing_content=existing_content   # ä¼ é€’åˆå§‹ä»£ç 
                )
                
                if fixed_content:
                    try:
                        # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
                        await self._save_file_content(file_path, fixed_content)
                        
                        # é¢å¤–ä¿éšœï¼šç›´æ¥ç¡®ä¿æ–‡ä»¶è¢«å†™å…¥
                        success = self._ensure_file_written(file_path, fixed_content)
                        if not success:
                            self.logger.warning(f"  âš ï¸ é¢å¤–æ–‡ä»¶å†™å…¥å°è¯•å¤±è´¥: {file_path}")
                        
                        fixed_files.append({
                            "path": file_path,
                            "type": "arkts",
                            "content": fixed_content,
                            "status": "fixed",
                            "errors_fixed": len(file_errors)
                        })
                        self.logger.info(f"  âœ“ æ–‡ä»¶ä¿®å¤æˆåŠŸ: {file_path}")
                        
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«ä¿å­˜
                        import os
                        if os.path.exists(file_path):
                            file_size = os.path.getsize(file_path)
                            self.logger.info(f"  âœ“ æ–‡ä»¶å­˜åœ¨äºç£ç›˜: {file_path}, å¤§å°: {file_size} å­—èŠ‚")
                            
                            # éªŒè¯æ–‡ä»¶å†…å®¹
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    saved_content = f.read()
                                
                                if saved_content == fixed_content:
                                    self.logger.info(f"  âœ“ æ–‡ä»¶å†…å®¹éªŒè¯æˆåŠŸ: {file_path}")
                                else:
                                    self.logger.warning(f"  âš ï¸ æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥: {file_path}, é•¿åº¦å·®å¼‚: {len(saved_content)} vs {len(fixed_content)}")
                            except Exception as read_error:
                                self.logger.warning(f"  âš ï¸ æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥: {file_path} - {read_error}")
                        else:
                            self.logger.error(f"  âœ— æ–‡ä»¶æœªä¿å­˜åˆ°ç£ç›˜: {file_path}")
                    except Exception as save_error:
                        self.logger.error(f"  âœ— ä¿å­˜æ–‡ä»¶å¤±è´¥: {file_path} - {save_error}")
                        import traceback
                        self.logger.error(f"  è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                        
                        # æœ€åå°è¯•ï¼šç›´æ¥å†™å…¥æ–‡ä»¶
                        try:
                            self.logger.info(f"  ğŸ”„ æœ€åå°è¯•ç›´æ¥å†™å…¥æ–‡ä»¶: {file_path}")
                            success = self._ensure_file_written(file_path, fixed_content)
                            if success:
                                self.logger.info(f"  âœ“ æœ€åå°è¯•æˆåŠŸ: {file_path}")
                                fixed_files.append({
                                    "path": file_path,
                                    "type": "arkts",
                                    "content": fixed_content,
                                    "status": "fixed",
                                    "errors_fixed": len(file_errors)
                                })
                            else:
                                self.logger.error(f"  âœ— æœ€åå°è¯•å¤±è´¥: {file_path}")
                        except Exception as final_error:
                            self.logger.error(f"  âœ— æœ€åå°è¯•å‡ºé”™: {file_path} - {final_error}")
                else:
                    self.logger.error(f"  âœ— æ–‡ä»¶ä¿®å¤å¤±è´¥: {file_path}")
            
            self.logger.info(f"é”™è¯¯ä¿®å¤å®Œæˆ: {len(fixed_files)} ä¸ªæ–‡ä»¶")
            
            return {
                "success": True,
                "fixed_files": fixed_files,
                "task_type": "error_fixing",
                "total_files_fixed": len(fixed_files),
                "total_errors_fixed": sum(len(errors_by_file[fp]) for fp in errors_by_file)
            }
            
        except Exception as e:
            self.logger.error(f"é”™è¯¯ä¿®å¤å¤±è´¥: {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "fixed_files": [],
                "task_type": "error_fixing"
            }
    
    async def _generate_file_content(self, file_plan: Dict[str, Any], context_info: str) -> str:
        """ä¸ºå•ä¸ªæ–‡ä»¶ç”Ÿæˆä»£ç å†…å®¹ - ç›´æ¥ä½¿ç”¨LLMè¾“å‡ºï¼Œé¿å…è¿‡åº¦æ¸…ç†"""
        try:
            file_path = file_plan.get("path", "")
            file_type = file_plan.get("type", "arkts")
            purpose = file_plan.get("purpose", "")
            content_outline = file_plan.get("content_outline", "")
            key_components = file_plan.get("key_components", [])
            
            # è·å–README.mdçš„å®é™…å†…å®¹ä½œä¸ºç”¨æˆ·éœ€æ±‚
            readme_content = self._read_readme_content()
            if not readme_content:
                readme_content = "Generate a simple ArkTS page component"
            
            # ä½¿ç”¨ç®€åŒ–çš„ä»£ç ç”Ÿæˆæ–¹æ³•ï¼Œé¿å…å¤æ‚çš„æ¸…ç†æœºåˆ¶
            from .simple_prompts import INITIAL_CODE_GENERATION_PROMPT
            
            # æ„å»ºä¸“é—¨çš„ä»£ç ç”Ÿæˆprompt
            prompt = INITIAL_CODE_GENERATION_PROMPT.format(
                user_requirements=readme_content,
                search_results=context_info or "No search results available"
            )
            
            # è°ƒç”¨LLMç”Ÿæˆä»£ç 
            if not self.llm_client:
                await self._initialize_llm()
            
            if self.llm_client:
                self.logger.info(f"ğŸ“¤ æ­£åœ¨ä¸ºæ–‡ä»¶ {file_path} è°ƒç”¨LLMç”Ÿæˆä»£ç ")
                self.logger.info(f"ğŸ“ ç”¨æˆ·éœ€æ±‚: {readme_content[:100]}...")
                
                messages = [{"role": "user", "content": prompt}]
                response = self.llm_client.chat(messages)
                
                # ç›´æ¥ä½¿ç”¨LLMçš„å“åº”ï¼Œæœ€å°ç¨‹åº¦çš„æ¸…ç†
                generated_code = self._simple_extract_code(response.content)
                
                self.logger.info(f"ğŸ“¥ LLMè¿”å›ä»£ç é•¿åº¦: {len(generated_code)} å­—ç¬¦")
                self.logger.info(f"ğŸ“¥ ä»£ç é¢„è§ˆ: {generated_code[:200]}...")
                
                if generated_code and len(generated_code.strip()) > 50:
                    self.logger.info(f"âœ… æ–‡ä»¶ä»£ç ç”ŸæˆæˆåŠŸ: {file_path}")
                    return generated_code
                else:
                    self.logger.warning(f"âš ï¸ LLMç”Ÿæˆçš„ä»£ç å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œé•¿åº¦: {len(generated_code)}")
                    # è®°å½•åŸå§‹å“åº”ç”¨äºè°ƒè¯•
                    self.logger.warning(f"ğŸ” åŸå§‹LLMå“åº”: {response.content[:500]}...")
                    raise ValueError("LLMç”Ÿæˆçš„ä»£ç æ— æ•ˆæˆ–ä¸ºç©º")
            else:
                raise ValueError("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                
        except Exception as e:
            self.logger.error(f"âŒ æ–‡ä»¶ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            # ä¸è¦å›é€€åˆ°ç¡¬ç¼–ç æ¨¡æ¿ï¼Œè€Œæ˜¯æŠ›å‡ºé”™è¯¯è®©è°ƒç”¨è€…å¤„ç†
            raise
    
    async def _fix_file_content(self, file_path: str, existing_content: str, 
                              file_errors: List[Dict], solution_references: List[Dict]) -> str:
        """ä¿®å¤æ–‡ä»¶å†…å®¹ - ä½¿ç”¨ç®€åŒ–æ–¹æ³•ï¼Œç›´æ¥è°ƒç”¨LLM"""
        try:
            # æ„å»ºé”™è¯¯ä¿¡æ¯
            error_messages = []
            for error in file_errors:
                error_msg = f"- ç¬¬{error.get('line', '?')}è¡Œ: {error.get('message', '')}"
                error_messages.append(error_msg)
            
            error_info = "\n".join(error_messages)
            
            # æ„å»ºè§£å†³æ–¹æ¡ˆä¿¡æ¯
            solutions_info = ""
            if solution_references:
                solutions_info = "å‚è€ƒè§£å†³æ–¹æ¡ˆ:\n"
                for i, solution in enumerate(solution_references[:3]):
                    solutions_info += f"{i+1}. {solution.get('content', '')}\n"
            
            # è·å–ç”¨æˆ·éœ€æ±‚
            readme_content = self._read_readme_content()
            if not readme_content:
                readme_content = "Fix compilation errors in Index.ets file"
            
            # ä½¿ç”¨ç®€åŒ–çš„é”™è¯¯ä¿®å¤prompt
            from .simple_prompts import ERROR_FIXING_PROMPT
            
            prompt = ERROR_FIXING_PROMPT.format(
                user_requirements=readme_content,
                original_code=existing_content,
                error_info=error_info,
                search_results=solutions_info or "No search results available"
            )
            
            # è°ƒç”¨LLMä¿®å¤ä»£ç 
            if not self.llm_client:
                await self._initialize_llm()
            
            if self.llm_client:
                self.logger.info(f"ğŸ“¤ æ­£åœ¨ä¿®å¤æ–‡ä»¶ {file_path} çš„é”™è¯¯")
                self.logger.info(f"ğŸ“ é”™è¯¯æ•°é‡: {len(file_errors)}")
                self.logger.info(f"ğŸ“ åŸä»£ç é•¿åº¦: {len(existing_content)} å­—ç¬¦")
                self.logger.info(f"ğŸ“ ç”¨æˆ·éœ€æ±‚é•¿åº¦: {len(readme_content)} å­—ç¬¦")
                self.logger.info(f"ğŸ“ é”™è¯¯ä¿¡æ¯é•¿åº¦: {len(error_info)} å­—ç¬¦")
                self.logger.info(f"ğŸ“ è§£å†³æ–¹æ¡ˆé•¿åº¦: {len(solutions_info)} å­—ç¬¦")
                
                # è®°å½•å‘é€ç»™LLMçš„å®Œæ•´ä¿¡æ¯
                self.logger.info(f"ğŸ“ ç”¨æˆ·éœ€æ±‚é¢„è§ˆ: {readme_content[:200]}...")
                self.logger.info(f"ğŸ“ é”™è¯¯ä¿¡æ¯é¢„è§ˆ: {error_info[:200]}...")
                
                messages = [{"role": "user", "content": prompt}]
                response = self.llm_client.chat(messages)
                
                # ä½¿ç”¨ç®€åŒ–çš„ä»£ç æå–æ–¹æ³•
                fixed_code = self._simple_extract_code(response.content)
                
                self.logger.info(f"ğŸ“¥ LLMè¿”å›ä¿®å¤ä»£ç é•¿åº¦: {len(fixed_code)} å­—ç¬¦")
                self.logger.info(f"ğŸ“¥ ä¿®å¤ä»£ç é¢„è§ˆ: {fixed_code[:200]}...")
                
                if fixed_code and len(fixed_code.strip()) > 50:
                    # æ£€æŸ¥ä¿®å¤åçš„ä»£ç æ˜¯å¦ä¸åŸä»£ç å®Œå…¨ç›¸åŒ
                    if fixed_code.strip() == existing_content.strip():
                        self.logger.warning(f"âš ï¸ LLMè¿”å›çš„ä¿®å¤ä»£ç ä¸åŸä»£ç å®Œå…¨ç›¸åŒï¼Œå¯èƒ½æœªè¿›è¡Œå®é™…ä¿®å¤")
                        self.logger.warning(f"ğŸ” é”™è¯¯ä¿¡æ¯: {error_info[:200]}...")
                        self.logger.warning(f"ğŸ” åŸå§‹LLMå“åº”: {response.content[:500]}...")
                        # è®°å½•é”™è¯¯ä½†ä»è¿”å›ä»£ç ï¼Œè®©åç»­æµç¨‹æ£€æµ‹åˆ°ä¿®å¤å¤±è´¥
                    
                    self.logger.info(f"âœ… æ–‡ä»¶é”™è¯¯ä¿®å¤æˆåŠŸ: {file_path}")
                    return fixed_code
                else:
                    self.logger.warning(f"âš ï¸ LLMä¿®å¤çš„ä»£ç å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œé•¿åº¦: {len(fixed_code)}")
                    self.logger.warning(f"ğŸ” åŸå§‹LLMå“åº”: {response.content[:500]}...")
                    self.logger.warning(f"ğŸ” é”™è¯¯ä¿¡æ¯: {error_info[:200]}...")
                    # è¿”å›åŸå†…å®¹ï¼Œä½†å¢åŠ è¯¦ç»†æ—¥å¿—
                    self.logger.warning(f"ğŸ”„ ä¿®å¤å¤±è´¥ï¼Œè¿”å›åŸå†…å®¹")
                    return existing_content
            else:
                raise ValueError("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                
        except Exception as e:
            self.logger.error(f"âŒ æ–‡ä»¶é”™è¯¯ä¿®å¤å¤±è´¥: {e}")
            # å¦‚æœå‡ºç°å¼‚å¸¸ï¼Œè¿”å›åŸå†…å®¹è€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
            return existing_content
    
    def _build_generation_context(self, project_plan: Dict, reference_materials: List[Dict]) -> str:
        """æ„å»ºä»£ç ç”Ÿæˆä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_parts = []
        
        # é¡¹ç›®åˆ†æä¿¡æ¯
        if project_plan:
            analysis = project_plan.get("requirement_analysis", {})
            if analysis:
                context_parts.append(f"é¡¹ç›®åŠŸèƒ½: {analysis.get('main_functionality', '')}")
                context_parts.append(f"å…³é”®ç‰¹æ€§: {', '.join(analysis.get('key_features', []))}")
        
        # å‚è€ƒèµ„æ–™
        if reference_materials:
            context_parts.append("å‚è€ƒèµ„æ–™:")
            for i, material in enumerate(reference_materials[:3]):  # æœ€å¤šä½¿ç”¨3ä¸ªå‚è€ƒèµ„æ–™
                content = material.get("content", "")[:200]  # é™åˆ¶é•¿åº¦
                context_parts.append(f"{i+1}. {content}")
        
        return "\n".join(context_parts)
    
    def _find_existing_file_content(self, file_path: str, existing_files: List[Dict]) -> str:
        """æŸ¥æ‰¾ç°æœ‰æ–‡ä»¶å†…å®¹"""
        self.logger.info(f"ğŸ” æŸ¥æ‰¾æ–‡ä»¶å†…å®¹: {file_path}")
        
        # å…ˆåœ¨ç°æœ‰æ–‡ä»¶åˆ—è¡¨ä¸­æŸ¥æ‰¾
        for file_info in existing_files:
            if file_info.get("path") == file_path:
                content = file_info.get("content", "")
                self.logger.info(f"   -> åœ¨ç°æœ‰æ–‡ä»¶åˆ—è¡¨ä¸­æ‰¾åˆ°ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                return content
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–
        try:
            import os
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                self.logger.info(f"   -> ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–ï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                return content
        except Exception as e:
            self.logger.warning(f"   -> è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        
        self.logger.info(f"   -> æœªæ‰¾åˆ°æ–‡ä»¶å†…å®¹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²")
        return ""
    
    async def _save_file_content(self, file_path: str, content: str):
        """ä¿å­˜æ–‡ä»¶å†…å®¹"""
        try:
            import os
            
            self.logger.info(f"å¼€å§‹ä¿å­˜æ–‡ä»¶: {file_path}")
            self.logger.info(f"æ–‡ä»¶å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # éªŒè¯æ–‡ä»¶è·¯å¾„
            if not file_path or not file_path.strip():
                self.logger.error(f"æ–‡ä»¶è·¯å¾„ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜æ–‡ä»¶")
                raise ValueError("æ–‡ä»¶è·¯å¾„ä¸ºç©º")
            
            # éªŒè¯å†…å®¹
            if not content:
                self.logger.warning(f"æ–‡ä»¶å†…å®¹ä¸ºç©º: {file_path}")
                content = "// ç©ºæ–‡ä»¶"
            
            # éªŒè¯æ–‡ä»¶è·¯å¾„æ ¼å¼
            if not file_path.startswith("MyApplication2/"):
                self.logger.warning(f"æ–‡ä»¶è·¯å¾„æ ¼å¼å¼‚å¸¸ï¼Œå°è¯•ä¿®å¤: {file_path}")
                if file_path.endswith(".ets"):
                    file_path = f"MyApplication2/entry/src/main/ets/pages/{os.path.basename(file_path)}"
                elif file_path.endswith(".json"):
                    file_path = f"MyApplication2/entry/src/main/resources/base/element/{os.path.basename(file_path)}"
                elif file_path.endswith(".json5"):
                    file_path = f"MyApplication2/entry/src/main/{os.path.basename(file_path)}"
                else:
                    # æ²¡æœ‰æ‰©å±•åï¼Œé»˜è®¤ä¸º.etsæ–‡ä»¶
                    file_path = f"MyApplication2/entry/src/main/ets/pages/{os.path.basename(file_path)}.ets"
                self.logger.info(f"ä¿®å¤åçš„æ–‡ä»¶è·¯å¾„: {file_path}")
            
            # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ˜¯Index.tsï¼Œç¡®ä¿ä¿®æ”¹ä¸ºIndex.ets
            if file_path.endswith("Index.ts"):
                old_path = file_path
                file_path = file_path.replace("Index.ts", "Index.ets")
                self.logger.info(f"å°†æ–‡ä»¶è·¯å¾„ä» {old_path} æ›´æ­£ä¸º {file_path}")
            
            # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿è·¯å¾„ä¸ä¸ºç©ºä¸”æœ‰æ•ˆ
            if not file_path or file_path.strip() == "":
                raise ValueError("ä¿®å¤åçš„æ–‡ä»¶è·¯å¾„ä»ä¸ºç©º")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            dir_path = os.path.dirname(file_path)
            if dir_path:
                os.makedirs(dir_path, exist_ok=True)
                self.logger.info(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
            
            # å†™å…¥æ–‡ä»¶å‰ï¼Œå…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_exists = os.path.exists(file_path)
            if file_exists:
                self.logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–: {file_path}")
                # å¤‡ä»½åŸæ–‡ä»¶
                import shutil
                backup_path = f"{file_path}.bak"
                shutil.copy2(file_path, backup_path)
                self.logger.info(f"å·²å¤‡ä»½åŸæ–‡ä»¶: {backup_path}")
            
            # ä½¿ç”¨ç¡®ä¿æ–‡ä»¶å†™å…¥çš„æ–¹æ³•
            success = self._ensure_file_written(file_path, content)
            
            if success:
                self.logger.info(f"æ–‡ä»¶æˆåŠŸå†™å…¥: {file_path}")
                
                # é¢å¤–éªŒè¯ï¼šç¡®è®¤æ–‡ä»¶å†…å®¹æ˜¯å¦æ­£ç¡®
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        saved_content = f.read()
                    
                    if saved_content == content:
                        self.logger.info(f"æ–‡ä»¶å†…å®¹éªŒè¯æˆåŠŸ: {file_path}")
                    else:
                        self.logger.warning(f"æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥: {file_path}, é•¿åº¦å·®å¼‚: {len(saved_content)} vs {len(content)}")
                except Exception as e:
                    self.logger.warning(f"æ–‡ä»¶å†…å®¹éªŒè¯å¤±è´¥: {file_path} - {e}")
            else:
                self.logger.error(f"æ–‡ä»¶å†™å…¥å¤±è´¥: {file_path}")
                raise ValueError(f"æ— æ³•å†™å…¥æ–‡ä»¶: {file_path}")
            
        except Exception as e:
            self.logger.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {file_path} - {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            raise
    
    async def _generate_file_content_with_prompt(self, file_plan: Dict[str, Any], project_plan: Dict[str, Any], reference_materials: List[Dict[str, Any]], workflow_type: str) -> str:
        """ä½¿ç”¨å·¥ä½œæµç‰¹å®šçš„æç¤ºè¯ç”Ÿæˆæ–‡ä»¶å†…å®¹"""
        try:
            # æ„å»ºå·¥ä½œæµç‰¹å®šçš„æç¤ºè¯
            workflow_prompt = self._build_harmonyos_prompt(workflow_type, {"file_plan": file_plan})
            
            # æ„å»ºæ–‡ä»¶ç‰¹å®šçš„ç”Ÿæˆè¯·æ±‚
            file_generation_prompt = f"""
{workflow_prompt}

Generate {file_plan.get('path', '')} for: {project_plan.get('requirement_analysis', {}).get('main_functionality', '')}
Reference: {self._format_reference_materials(reference_materials)}
Output code only:
"""
            
            if self.llm_client:
                messages = [{"role": "user", "content": file_generation_prompt}]
                response = self.llm_client.chat(messages)
                
                if hasattr(response, 'content'):
                    return response.content.strip()
                else:
                    return str(response).strip()
            else:
                self.logger.error("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return ""
                
        except Exception as e:
            self.logger.error(f"æ–‡ä»¶å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            return ""
    
    def _format_reference_materials(self, reference_materials: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å‚è€ƒèµ„æ–™"""
        if not reference_materials:
            return "æ— å‚è€ƒèµ„æ–™"
        
        formatted = []
        for i, material in enumerate(reference_materials[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
            content = material.get('content', '')
            if len(content) > 200:
                content = content[:200] + "..."
            formatted.append(f"{i+1}. {content}")
        
        return "\n".join(formatted)
    
    async def _fix_file_errors_with_prompt(self, file_path: str, file_errors: List[Dict[str, Any]], existing_files: List[Dict[str, Any]], solution_references: List[Dict[str, Any]], workflow_type: str, user_requirement: str = "", existing_content: str = "") -> str:
        """ä½¿ç”¨å·¥ä½œæµç‰¹å®šçš„æç¤ºè¯ä¿®å¤æ–‡ä»¶é”™è¯¯"""
        try:
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„ç°æœ‰å†…å®¹ï¼ˆåˆå§‹ä»£ç ï¼‰
            current_content = existing_content
            
            # å¦‚æœæ²¡æœ‰ä¼ å…¥ç°æœ‰å†…å®¹ï¼Œä»æ–‡ä»¶ç³»ç»Ÿè¯»å–
            if not current_content:
                for existing_file in existing_files:
                    if existing_file.get("path") == file_path:
                        current_content = existing_file.get("content", "")
                        break
            
            # å¦‚æœä»ç„¶æ²¡æœ‰å†…å®¹ï¼Œå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿç›´æ¥è¯»å–
            if not current_content and os.path.exists(file_path):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        current_content = f.read()
                except Exception as e:
                    self.logger.warning(f"ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–ç°æœ‰å†…å®¹å¤±è´¥: {e}")
            
            if not current_content:
                # å°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–
                try:
                    import os
                    if os.path.exists(file_path):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            current_content = f.read()
                except Exception as e:
                    self.logger.warning(f"æ— æ³•è¯»å–ç°æœ‰æ–‡ä»¶ {file_path}: {e}")
            
            # è·å–README.mdçš„éœ€æ±‚å†…å®¹
            readme_content = self._read_readme_content()
            if not readme_content:
                readme_content = "ç”Ÿæˆä¸€ä¸ªç®€å•çš„ArkTSé¡µé¢ç»„ä»¶"
                
            self.logger.info(f"ä¸ºé”™è¯¯ä¿®å¤è¯»å–README.mdéœ€æ±‚: {len(readme_content)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é¡¹ç›®ç®¡ç†Agentçš„ç²¾ç¡®åˆ†æ
            has_analysis = any(error.get('from_analysis', False) for error in file_errors)
            
            # è·å–åŸå§‹é”™è¯¯è¾“å‡ºï¼ˆç‰¹åˆ«æ˜¯å¯¹äºç¼–è¯‘é”™è¯¯ï¼‰
            raw_error_outputs = []
            for error in file_errors:
                if error.get('raw_message') and error.get('raw_message') not in raw_error_outputs:
                    raw_error_outputs.append(error.get('raw_message'))
                elif error.get('raw_output') and error.get('raw_output') not in raw_error_outputs:
                    raw_error_outputs.append(error.get('raw_output'))
            
            # ä»åŸå§‹è¾“å‡ºä¸­æå–ç¼–è¯‘ç»Ÿè®¡ä¿¡æ¯
            import re
            error_stats = {}
            for raw_output in raw_error_outputs:
                if not raw_output:
                    continue
                # æŸ¥æ‰¾ç¼–è¯‘ç»Ÿè®¡ä¿¡æ¯
                stats_match = re.search(r'COMPILE RESULT:(?:FAIL|PASS) \{ERROR:(\d+) WARN:(\d+)\}', raw_output)
                if stats_match:
                    error_stats["errors"] = int(stats_match.group(1))
                    error_stats["warnings"] = int(stats_match.group(2))
                    self.logger.info(f"ä»åŸå§‹è¾“å‡ºä¸­æå–åˆ°ç¼–è¯‘ç»Ÿè®¡: {error_stats['errors']}ä¸ªé”™è¯¯, {error_stats['warnings']}ä¸ªè­¦å‘Š")
            
            # å¦‚æœç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤ºæ²¡æœ‰é”™è¯¯ï¼Œä½†æˆ‘ä»¬æ”¶åˆ°äº†é”™è¯¯å¯¹è±¡ï¼Œå¯èƒ½æ˜¯è¯¯æŠ¥
            if error_stats.get("errors") == 0 and len(file_errors) > 0:
                self.logger.warning(f"ç¼–è¯‘ç»Ÿè®¡æ˜¾ç¤ºæ²¡æœ‰é”™è¯¯ï¼Œä½†æ”¶åˆ°äº†{len(file_errors)}ä¸ªé”™è¯¯å¯¹è±¡ï¼Œå¯èƒ½æ˜¯è¯¯æŠ¥")
                # æˆ‘ä»¬ä»ç„¶ç»§ç»­å¤„ç†ï¼Œä½†è®°å½•è­¦å‘Š
            
            if has_analysis:
                # ä½¿ç”¨é¡¹ç›®ç®¡ç†Agentçš„ç²¾ç¡®åˆ†æ
                errors_description = "\n".join([
                    f"**é”™è¯¯ {error.get('error_id', i+1)}:**\n"
                    f"- åŸå§‹é”™è¯¯: {error.get('message', '')}\n"
                    f"- æ ¹æœ¬åŸå› : {error.get('root_cause', 'æœªçŸ¥')}\n"
                    f"- ä¿®å¤ä½ç½®: {error.get('fix_location', 'æœªæŒ‡å®š')}\n"
                    f"- ä¿®å¤æè¿°: {error.get('fix_description', 'éœ€è¦ä¿®å¤é”™è¯¯')}\n"
                    for i, error in enumerate(file_errors)
                ])
            else:
                # å¤‡ç”¨ï¼šä½¿ç”¨åŸå§‹é”™è¯¯ä¿¡æ¯
                errors_description = "\n".join([
                    f"- ç±»å‹: {error.get('error_type', 'unknown')}, æ¶ˆæ¯: {error.get('message', '')}, è¡Œå·: {error.get('line', 'N/A')}, ä¸¥é‡æ€§: {error.get('severity', 'unknown')}"
                    for error in file_errors
                ])
                
                # æ·»åŠ åŸå§‹é”™è¯¯è¾“å‡ºï¼ˆç‰¹åˆ«æ˜¯å¯¹äºç¼–è¯‘é”™è¯¯ï¼‰
                if raw_error_outputs:
                    errors_description += "\n\nåŸå§‹é”™è¯¯è¾“å‡º:\n"
                    for i, raw_output in enumerate(raw_error_outputs[:3]):  # æœ€å¤šåŒ…å«3ä¸ªåŸå§‹è¾“å‡º
                        errors_description += f"--- åŸå§‹è¾“å‡º {i+1} ---\n{raw_output[:500]}...\n"  # é™åˆ¶é•¿åº¦
            
            solution_info = "\n".join([
                f"- {solution.get('content', '')[:150]}..."
                for solution in solution_references[:3]
            ]) if solution_references else "æ— å¯ç”¨è§£å†³æ–¹æ¡ˆ"
            
            # ä½¿ç”¨ç®€åŒ–çš„é”™è¯¯ä¿®å¤æç¤ºè¯
            from .simple_prompts import ERROR_FIXING_PROMPT
            
            fix_prompt = ERROR_FIXING_PROMPT.format(
                user_requirements=f"åŸå§‹éœ€æ±‚: {user_requirement}\n\nä¿®å¤æ–‡ä»¶: {file_path}",
                original_code=current_content,
                error_info=errors_description,
                search_results=solution_info
            )
            
            # ç¡®ä¿LLMå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
            await self._initialize_llm()
            
            if self.llm_client:
                # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼Œå¼ºè°ƒåªè¾“å‡ºçº¯ä»£ç 
                system_prompt = """You are a HarmonyOS ArkTS code repair specialist.

ABSOLUTE REQUIREMENTS - STRICTLY ENFORCED:
1. Output ONLY executable ArkTS code - ZERO explanations, comments, documentation
2. FORBIDDEN: ``` markdown blocks, ä¸­æ–‡å­—ç¬¦, explanatory text, code descriptions
3. START: Direct import statements or @Entry decorator
4. END: Final closing brace }
5. NO text before code, NO text after code, NO headers, NO summaries
6. Fix ONLY compilation-blocking ERROR level issues (ignore warnings)
7. Preserve original code logic, variable names, and structure
8. Use only standard HarmonyOS ArkTS syntax and APIs
9. Ensure @Entry, @Component decorators are properly placed
10. Maintain original functionality while fixing syntax/compilation errors

IMMEDIATE CODE OUTPUT REQUIRED - NO PREAMBLE:"""
                
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": fix_prompt}
                ]
                
                response = self.llm_client.chat(messages)
                
                # ä½¿ç”¨å¢å¼ºçš„ä»£ç æå–æ–¹æ³•
                fixed_code = self._extract_code_from_response(response.content)
                
                self.logger.info(f"æ–‡ä»¶é”™è¯¯ä¿®å¤å®Œæˆ: {file_path}")
                self.logger.info(f"ä»£ç æå–ç»“æœé•¿åº¦: {len(fixed_code)} å­—ç¬¦")
                
                # éªŒè¯æå–çš„ä»£ç æ˜¯å¦ä¸ºç©º
                if not fixed_code.strip():
                    self.logger.warning("æå–çš„ä»£ç ä¸ºç©ºï¼Œå°è¯•ç®€å•æ¸…ç†")
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•æ¸…ç†ä¸­æ–‡å’Œmarkdownæ ‡è®°
                    fixed_code = self.simple_fix_code(
                        f"åŸå§‹éœ€æ±‚: {readme_content}\n\nä¿®å¤æ–‡ä»¶: {file_path}", 
                        current_content, 
                        errors_description, 
                        solution_info
                    )
                
                return fixed_code
            else:
                self.logger.error("LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return ""
                
        except Exception as e:
            self.logger.error(f"ä½¿ç”¨æç¤ºè¯ä¿®å¤æ–‡ä»¶é”™è¯¯å¤±è´¥: {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return ""
            
    
    async def _initialize_llm(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆå¦‚æœæœªåˆå§‹åŒ–ï¼‰"""
        if not self.llm_client:
            try:
                await self.initialize()
            except Exception as e:
                self.logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _read_existing_index_file(self) -> str:
        """è¯»å–ç°æœ‰çš„Index.etsæ–‡ä»¶å†…å®¹"""
        try:
            index_file_path = self.myapplication2_path / "entry/src/main/ets/pages/Index.ets"
            
            if not index_file_path.exists():
                return ""
            
            with open(index_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            return content
            
        except Exception as e:
            self.logger.error(f"è¯»å–Index.etsæ–‡ä»¶å¤±è´¥: {e}")
            return ""
    
    def _read_project_dependencies(self) -> Dict[str, Any]:
        """è¯»å–é¡¹ç›®ä¾èµ–ä¿¡æ¯"""
        try:
            dependencies_info = {}
            
            # è¯»å–oh-package.json5æ–‡ä»¶
            oh_package_path = self.myapplication2_path / "oh-package.json5"
            if oh_package_path.exists():
                with open(oh_package_path, 'r', encoding='utf-8') as f:
                    dependencies_info["oh_package"] = f.read()
            
            # è¯»å–entry/oh-package.json5æ–‡ä»¶
            entry_package_path = self.myapplication2_path / "entry/oh-package.json5"
            if entry_package_path.exists():
                with open(entry_package_path, 'r', encoding='utf-8') as f:
                    dependencies_info["entry_package"] = f.read()
            
            # è¯»å–module.json5æ–‡ä»¶
            module_path = self.myapplication2_path / "entry/src/main/module.json5"
            if module_path.exists():
                with open(module_path, 'r', encoding='utf-8') as f:
                    dependencies_info["module"] = f.read()
            
            return dependencies_info
            
        except Exception as e:
            self.logger.error(f"è¯»å–é¡¹ç›®ä¾èµ–å¤±è´¥: {e}")
            return {}
    
    def _get_project_context_for_code_generation(self) -> str:
        """ä¸ºä»£ç ç”Ÿæˆè·å–é¡¹ç›®ä¸Šä¸‹æ–‡"""
        try:
            context_parts = []
            
            # è¯»å–ç°æœ‰çš„Index.etsæ–‡ä»¶
            existing_content = self._read_existing_index_file()
            if existing_content:
                context_parts.append("=== ç°æœ‰Index.etsæ–‡ä»¶å†…å®¹ ===")
                context_parts.append(existing_content)
            
            # è¯»å–é¡¹ç›®ä¾èµ–ä¿¡æ¯
            dependencies = self._read_project_dependencies()
            if dependencies:
                context_parts.append("\n=== é¡¹ç›®ä¾èµ–ä¿¡æ¯ ===")
                for dep_type, content in dependencies.items():
                    context_parts.append(f"\n--- {dep_type} ---")
                    context_parts.append(content[:500])  # é™åˆ¶é•¿åº¦
            
            return "\n".join(context_parts)
            
        except Exception as e:
            self.logger.error(f"è·å–é¡¹ç›®ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return "" 
    
    def _ensure_file_written(self, file_path: str, content: str) -> bool:
        """ç¡®ä¿æ–‡ä»¶è¢«æ­£ç¡®å†™å…¥ç£ç›˜ï¼Œä½¿ç”¨å¤šç§æ–¹æ³•å°è¯•"""
        try:
            import os
            import pathlib
            
            self.logger.info(f"ç¡®ä¿æ–‡ä»¶å†™å…¥: {file_path}")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # æ–¹æ³•1: ä½¿ç”¨æ ‡å‡†openå†™å…¥
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                self.logger.info(f"æ–¹æ³•1æˆåŠŸ: {file_path}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    return True
            except Exception as e:
                self.logger.warning(f"æ–¹æ³•1å¤±è´¥: {e}")
            
            # æ–¹æ³•2: ä½¿ç”¨pathlibå†™å…¥
            try:
                pathlib.Path(file_path).write_text(content, encoding='utf-8')
                self.logger.info(f"æ–¹æ³•2æˆåŠŸ: {file_path}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    return True
            except Exception as e:
                self.logger.warning(f"æ–¹æ³•2å¤±è´¥: {e}")
            
            # æ–¹æ³•3: ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç„¶åé‡å‘½å
            try:
                import tempfile
                import shutil
                
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as temp:
                    temp.write(content)
                    temp_name = temp.name
                
                # å¤åˆ¶ä¸´æ—¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
                shutil.copy2(temp_name, file_path)
                os.unlink(temp_name)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                
                self.logger.info(f"æ–¹æ³•3æˆåŠŸ: {file_path}")
                
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    return True
            except Exception as e:
                self.logger.warning(f"æ–¹æ³•3å¤±è´¥: {e}")
            
            # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
            self.logger.error(f"æ‰€æœ‰å†™å…¥æ–¹æ³•éƒ½å¤±è´¥: {file_path}")
            return False
            
        except Exception as e:
            self.logger.error(f"ç¡®ä¿æ–‡ä»¶å†™å…¥å¤±è´¥: {file_path} - {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False
    
    def _read_readme_requirement(self) -> str:
        """è¯»å–MyApplication2/README.mdä¸­çš„ç”¨æˆ·éœ€æ±‚æè¿°"""
        try:
            readme_path = self.myapplication2_path / "README.md"
            
            if not readme_path.exists():
                self.logger.warning(f"README.mdæ–‡ä»¶ä¸å­˜åœ¨: {readme_path}")
                return ""
            
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–è‡ªç„¶è¯­è¨€æè¿°éƒ¨åˆ†
            lines = content.split('\n')
            description_lines = []
            start_capturing = False
            
            for line in lines:
                if "è‡ªç„¶è¯­è¨€æè¿°" in line:
                    start_capturing = True
                    continue
                
                if start_capturing:
                    # å¦‚æœé‡åˆ°æ–°çš„markdownæ ‡é¢˜ï¼Œåœæ­¢æ•è·
                    if line.strip().startswith('##') and not line.strip().startswith('###'):
                        break
                    
                    # è·³è¿‡ç©ºè¡Œå’Œmarkdownè¯­æ³•ï¼Œä½†ä¿ç•™å†…å®¹
                    if line.strip() and not line.strip().startswith('---'):
                        description_lines.append(line.strip())
            
            description = '\n'.join(description_lines)
            self.logger.info(f"ä»README.mdæå–è‡ªç„¶è¯­è¨€æè¿°: {len(description)} å­—ç¬¦")
            
            return description if description else content
            
        except Exception as e:
            self.logger.error(f"è¯»å–README.mdæ–‡ä»¶å¤±è´¥: {e}")
            return ""