#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é”™è¯¯ä¿®å¤å·¥ä½œæµä¸“ç”¨æµ‹è¯•å…¥å£ - å·¥ä½œæµäºŒæµ‹è¯•å·¥å…·
ä¸“é—¨ç”¨äºæµ‹è¯•é”™è¯¯ä¿®å¤å·¥ä½œæµï¼Œä»ç°æœ‰é”™è¯¯ä»£ç å¼€å§‹è¿›è¡Œé™æ€æ£€æŸ¥ã€ç¼–è¯‘æ£€æŸ¥å’Œå¾ªç¯ä¿®å¤
"""

import argparse
import asyncio
import json
import sys
import os
import time
import logging
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from mcp_orchestrator import MCPCoordinator
from mcp_orchestrator.collaborative_workflow import CollaborativeWorkflowManager
from mcp_orchestrator.workflow_context import (
    WorkflowContext, WorkflowPhase, TaskType, FileInfo, ErrorInfo
)
from shared.config_loader import ConfigLoader

# é…ç½®æ—¥å¿— - å¼ºåˆ¶æ˜¾ç¤º
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('error_fix_workflow_test.log')
    ],
    force=True  # Python 3.8+ å¼ºåˆ¶é‡æ–°é…ç½®
)

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ç¡®ä¿æ ¹loggerä¹Ÿè¾“å‡º
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)


class ErrorFixWorkflowTester:
    """é”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.coordinator = None
        self.workflow_manager = None
        self.config_loader = ConfigLoader()
    
    async def initialize(self, config_file: str = None) -> bool:
        """åˆå§‹åŒ–åè°ƒå™¨å’Œå·¥ä½œæµç®¡ç†å™¨"""
        try:
            # åŠ è½½é…ç½®
            if config_file:
                config = self.config_loader.load_config(config_file)
            else:
                config = self.config_loader.get_unified_config()
                if not config:
                    logger.warning("ç»Ÿä¸€é…ç½®ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                    config = self.config_loader._get_default_unified_config()
            
            # åˆ›å»ºåè°ƒå™¨
            print("ğŸ”§ æ­£åœ¨åˆ›å»ºMCPåè°ƒå™¨...")
            self.coordinator = MCPCoordinator(config)
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–åè°ƒå™¨...")
            await self.coordinator.initialize()
            
            # åˆ›å»ºåä½œå¼å·¥ä½œæµç®¡ç†å™¨
            print("ğŸ”§ æ­£åœ¨åˆ›å»ºåä½œå¼å·¥ä½œæµç®¡ç†å™¨...")
            self.workflow_manager = CollaborativeWorkflowManager(self.coordinator)
            
            print("ğŸš€ é”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•å™¨åˆå§‹åŒ–æˆåŠŸ")
            logger.info("ğŸš€ é”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def test_error_fix_workflow(self, user_requirement: str = "æµ‹è¯•é”™è¯¯ä¿®å¤å·¥ä½œæµ", 
                                    session_id: str = None) -> Dict[str, Any]:
        """
        æµ‹è¯•é”™è¯¯ä¿®å¤å·¥ä½œæµäºŒ
        
        Args:
            user_requirement: æ¨¡æ‹Ÿç”¨æˆ·éœ€æ±‚ï¼ˆç”¨äºæœç´¢å…³é”®è¯ç”Ÿæˆï¼‰
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
        
        Returns:
            å·¥ä½œæµæ‰§è¡Œç»“æœ
        """
        try:
            if not session_id:
                session_id = f"error_fix_test_{int(time.time())}"
            
            print("=" * 80)
            print("ğŸ”§ å¼€å§‹æµ‹è¯•é”™è¯¯ä¿®å¤å·¥ä½œæµäºŒ")
            print(f"   - ä¼šè¯ID: {session_id}")
            print(f"   - ç”¨æˆ·éœ€æ±‚: {user_requirement}")
            print(f"   - æµ‹è¯•ç›®æ ‡: Index.etsæ–‡ä»¶çš„é”™è¯¯æ£€æŸ¥å’Œä¿®å¤")
            print("=" * 80)
            
            logger.info("=" * 80)
            logger.info("ğŸ”§ å¼€å§‹æµ‹è¯•é”™è¯¯ä¿®å¤å·¥ä½œæµäºŒ")
            logger.info(f"   - ä¼šè¯ID: {session_id}")
            logger.info(f"   - ç”¨æˆ·éœ€æ±‚: {user_requirement}")
            logger.info(f"   - æµ‹è¯•ç›®æ ‡: Index.etsæ–‡ä»¶çš„é”™è¯¯æ£€æŸ¥å’Œä¿®å¤")
            logger.info("=" * 80)
            
            # 1. æ£€æŸ¥Index.etsæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            index_file_path = "/home/deepsearch/deep-searcher/MyApplication2/entry/src/main/ets/pages/Index.ets"
            if not os.path.exists(index_file_path):
                return {
                    "success": False,
                    "error": f"Index.etsæ–‡ä»¶ä¸å­˜åœ¨: {index_file_path}",
                    "suggestion": "è¯·ç¡®ä¿Index.etsæ–‡ä»¶å·²å‡†å¤‡å¥½å¹¶åŒ…å«æœ‰é”™è¯¯çš„ä»£ç "
                }
            
            # 2. åˆ›å»ºé”™è¯¯ä¿®å¤å·¥ä½œæµä¸Šä¸‹æ–‡
            context = self._create_error_fix_context(session_id, user_requirement, index_file_path)
            
            logger.info("âœ… é”™è¯¯ä¿®å¤å·¥ä½œæµä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")
            logger.info(f"   - å½“å‰é˜¶æ®µ: {context.current_phase.value}")
            logger.info(f"   - ä»»åŠ¡ç±»å‹: {context.current_task_type.value}")
            logger.info(f"   - ç›®æ ‡æ–‡ä»¶: {index_file_path}")
            
            # 3. é¦–å…ˆæ‰§è¡Œé™æ€æ£€æŸ¥ï¼ˆä»£ç æ£€æŸ¥Agentï¼‰
            logger.info("\nğŸ” æ­¥éª¤1: æ‰§è¡Œé™æ€æ£€æŸ¥ (codelinter)")
            static_check_success = await self._execute_static_check(context)
            if not static_check_success:
                return {
                    "success": False,
                    "error": "é™æ€æ£€æŸ¥å¤±è´¥",
                    "context": context.to_dict()
                }
            
            # 4. æ‰§è¡Œç¼–è¯‘æ£€æŸ¥ï¼ˆé¡¹ç›®ç®¡ç†Agentï¼‰
            logger.info("\nğŸ”§ æ­¥éª¤2: æ‰§è¡Œç¼–è¯‘æ£€æŸ¥ (hvigorw)")
            compile_check_success = await self._execute_compile_check(context)
            if not compile_check_success:
                return {
                    "success": False,
                    "error": "ç¼–è¯‘æ£€æŸ¥å¤±è´¥",
                    "context": context.to_dict()
                }
            
            # 5. æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯éœ€è¦ä¿®å¤ - ä½¿ç”¨æ­£ç¡®çš„é”™è¯¯æ£€æŸ¥æ–¹æ³•
            has_actual_errors = context.has_errors()
            total_lint_count = len(context.lint_errors)
            total_compile_count = len(context.compile_errors)
            
            print(f"\nğŸ“Š é”™è¯¯æ£€æŸ¥ç»“æœ:")
            print(f"   - é™æ€æ£€æŸ¥é”™è¯¯åˆ—è¡¨æ•°é‡: {total_lint_count}")
            print(f"   - ç¼–è¯‘é”™è¯¯åˆ—è¡¨æ•°é‡: {total_compile_count}")
            print(f"   - å®é™…æœ‰é”™è¯¯éœ€è¦ä¿®å¤: {has_actual_errors}")
            
            if not has_actual_errors:
                logger.info("âœ… æ²¡æœ‰å‘ç°å®é™…é”™è¯¯ï¼Œæ— éœ€è¿›å…¥ä¿®å¤å·¥ä½œæµ")
                return {
                    "success": True,
                    "message": "ä»£ç æ£€æŸ¥é€šè¿‡ï¼Œæ²¡æœ‰å‘ç°å®é™…é”™è¯¯",
                    "static_errors": total_lint_count,
                    "compile_errors": total_compile_count,
                    "actual_errors": False,
                    "context": context.to_dict()
                }
            
            print(f"\nâš ï¸ å‘ç°å®é™…é”™è¯¯ï¼Œå¼€å§‹æ‰§è¡Œé”™è¯¯ä¿®å¤å·¥ä½œæµ")
            logger.info(f"\nâš ï¸ å‘ç°å®é™…é”™è¯¯ï¼Œå¼€å§‹æ‰§è¡Œé”™è¯¯ä¿®å¤å·¥ä½œæµ")
            logger.info(f"   - é™æ€æ£€æŸ¥é”™è¯¯åˆ—è¡¨: {total_lint_count}ä¸ª")
            logger.info(f"   - ç¼–è¯‘é”™è¯¯åˆ—è¡¨: {total_compile_count}ä¸ª")
            logger.info(f"   - å®é™…éœ€è¦ä¿®å¤: {has_actual_errors}")
            
            # 6. æ‰§è¡Œé”™è¯¯ä¿®å¤å·¥ä½œæµ
            logger.info("\nğŸ”„ å¼€å§‹æ‰§è¡Œé”™è¯¯ä¿®å¤å¾ªç¯")
            fix_result = await self.workflow_manager._execute_error_fixing_workflow(context)
            
            # 7. ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_result = self._generate_final_result(context, fix_result)
            
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“Š é”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•å®Œæˆ")
            self._print_test_summary(final_result)
            logger.info("=" * 80)
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ é”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
            import traceback
            logger.error(f"ğŸ“‹ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "context": context.to_dict() if 'context' in locals() else {}
            }
    
    def _create_error_fix_context(self, session_id: str, user_requirement: str, 
                                 index_file_path: str) -> WorkflowContext:
        """åˆ›å»ºé”™è¯¯ä¿®å¤å·¥ä½œæµä¸Šä¸‹æ–‡"""
        # è¯»å–å½“å‰Index.etsæ–‡ä»¶å†…å®¹
        try:
            with open(index_file_path, 'r', encoding='utf-8') as f:
                file_content = f.read()
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–Index.etsæ–‡ä»¶: {e}")
            file_content = ""
        
        # åˆ›å»ºå·¥ä½œæµä¸Šä¸‹æ–‡ï¼Œç›´æ¥è®¾ç½®ä¸ºé”™è¯¯ä¿®å¤æ¨¡å¼
        context = WorkflowContext(
            session_id=session_id,
            user_requirement=user_requirement,
            current_phase=WorkflowPhase.STATIC_CHECK,  # ä»é™æ€æ£€æŸ¥å¼€å§‹
            current_task_type=TaskType.INITIAL_GENERATION  # å…ˆè®¾ä¸ºåˆå§‹ç”Ÿæˆï¼Œæ£€æŸ¥åä¼šåˆ‡æ¢ä¸ºä¿®å¤
        )
        
        # æ·»åŠ ç°æœ‰æ–‡ä»¶ä¿¡æ¯
        existing_file = FileInfo(
            path="MyApplication2/entry/src/main/ets/pages/Index.ets",
            type="arkts",
            content=file_content,
            status="generated"  # å‡è®¾æ–‡ä»¶å·²å­˜åœ¨
        )
        context.generated_files.append(existing_file)
        
        return context
    
    async def _execute_static_check(self, context: WorkflowContext) -> bool:
        """æ‰§è¡Œé™æ€æ£€æŸ¥"""
        try:
            context.current_phase = WorkflowPhase.STATIC_CHECK
            
            # è°ƒç”¨ä»£ç æ£€æŸ¥Agent
            agent_context = context.get_generation_context_for_agent("code_checker")
            logger.info(f"ğŸ“¤ å‘é€ç»™ä»£ç æ£€æŸ¥Agentçš„ä¸Šä¸‹æ–‡: {list(agent_context.keys())}")
            logger.info(f"   - æ£€æŸ¥æ–‡ä»¶æ•°: {len(agent_context.get('files_to_check', []))}")
            logger.info(f"   - é¡¹ç›®è·¯å¾„: MyApplication2")
            
            result = await asyncio.wait_for(
                self.coordinator._execute_agent_method(
                    "code_checker", 
                    "code.check.harmonyos", 
                    agent_context
                ),
                timeout=90.0  # 1.5åˆ†é’Ÿè¶…æ—¶
            )
            
            logger.info(f"ğŸ“¥ ä»£ç æ£€æŸ¥Agentè¿”å›ç»“æœ: success={result.get('success')}")
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.update_from_agent_result("code_checker", result)
            
            total_errors = result.get('total_errors', 0)
            total_warnings = result.get('total_warnings', 0)
            
            if result.get("success"):
                logger.info(f"   - é”™è¯¯æ•°é‡: {total_errors}")
                logger.info(f"   - è­¦å‘Šæ•°é‡: {total_warnings}")
                logger.info(f"   - æ£€æŸ¥ç±»å‹: {result.get('check_type', 'N/A')}")
                
                if len(context.lint_errors) > 0:
                    logger.warning(f"âš ï¸ é™æ€æ£€æŸ¥å‘ç° {len(context.lint_errors)} ä¸ªé”™è¯¯")
                else:
                    logger.info(f"âœ… é™æ€æ£€æŸ¥æˆåŠŸï¼Œæ— é”™è¯¯")
                return True
            else:
                logger.error(f"âŒ é™æ€æ£€æŸ¥å¤±è´¥: {result.get('error', 'N/A')}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ é™æ€æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    async def _execute_compile_check(self, context: WorkflowContext) -> bool:
        """æ‰§è¡Œç¼–è¯‘æ£€æŸ¥"""
        try:
            context.current_phase = WorkflowPhase.COMPILE_CHECK
            
            # è°ƒç”¨é¡¹ç›®ç®¡ç†Agentè¿›è¡Œç¼–è¯‘æ£€æŸ¥
            agent_context = context.get_generation_context_for_agent("project_manager")
            logger.info(f"ğŸ“¤ å‘é€ç»™é¡¹ç›®ç®¡ç†Agentçš„ç¼–è¯‘ä¸Šä¸‹æ–‡: {list(agent_context.keys())}")
            logger.info(f"   - é¡¹ç›®è·¯å¾„: {agent_context.get('project_path', 'N/A')}")
            logger.info(f"   - ä»»åŠ¡æè¿°: {agent_context.get('task_description', 'N/A')}")
            
            result = await asyncio.wait_for(
                self.coordinator._execute_agent_method(
                    "project_manager", 
                    "project.hvigor_compile", 
                    agent_context
                ),
                timeout=180.0  # 3åˆ†é’Ÿè¶…æ—¶
            )
            
            logger.info(f"ğŸ“¥ é¡¹ç›®ç®¡ç†Agentç¼–è¯‘ç»“æœ: success={result.get('success')}")
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context.update_from_agent_result("project_manager", result)
            
            compile_result = result.get('compile_result', {})
            errors = compile_result.get('errors', [])
            warnings = compile_result.get('warnings', [])
            
            logger.info(f"   - ç¼–è¯‘çŠ¶æ€: {compile_result.get('status', 'N/A')}")
            logger.info(f"   - è¿”å›ç : {compile_result.get('returncode', 'N/A')}")
            logger.info(f"   - é”™è¯¯æ•°é‡: {len(errors)}")
            logger.info(f"   - è­¦å‘Šæ•°é‡: {len(warnings)}")
            
            if result.get("success"):
                if len(context.compile_errors) > 0:
                    logger.warning(f"âš ï¸ ç¼–è¯‘æ£€æŸ¥å‘ç° {len(context.compile_errors)} ä¸ªç¼–è¯‘é”™è¯¯")
                else:
                    logger.info(f"âœ… ç¼–è¯‘æ£€æŸ¥æˆåŠŸï¼Œæ— é”™è¯¯")
                return True
            else:
                logger.warning(f"âš ï¸ ç¼–è¯‘æ£€æŸ¥å¤±è´¥: {result.get('error', 'N/A')}")
                # æ˜¾ç¤ºå‰å‡ ä¸ªé”™è¯¯
                for i, error in enumerate(errors[:2]):
                    logger.info(f"     é”™è¯¯{i+1}: {error.get('message', 'N/A')}")
                return True  # å³ä½¿ç¼–è¯‘å¤±è´¥ä¹Ÿç»§ç»­ï¼Œè®©ä¿®å¤å·¥ä½œæµå¤„ç†
                
        except Exception as e:
            logger.error(f"âŒ ç¼–è¯‘æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def _generate_final_result(self, context: WorkflowContext, fix_result: bool) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæµ‹è¯•ç»“æœ"""
        # ä½¿ç”¨æ­£ç¡®çš„é”™è¯¯æ£€æŸ¥æ–¹æ³•
        has_actual_errors = context.has_errors()
        lint_count = len(context.lint_errors)
        compile_count = len(context.compile_errors)
        
        return {
            "success": fix_result,
            "session_id": context.session_id,
            "workflow_type": "error_fix_test",
            "test_summary": {
                "fix_attempts": context.fix_attempts,
                "max_fix_attempts": context.max_fix_attempts,
                "workflow_completed": context.workflow_completed,
                "final_error_count": lint_count + compile_count,  # åˆ—è¡¨æ•°é‡
                "actual_errors": has_actual_errors,  # å®é™…æ˜¯å¦æœ‰é”™è¯¯
                "static_errors": lint_count,
                "compile_errors": compile_count
            },
            "generated_files": [file.__dict__ for file in context.generated_files],
            "error_details": {
                "lint_errors": [error.__dict__ for error in context.lint_errors],
                "compile_errors": [error.__dict__ for error in context.compile_errors],
                "has_actual_errors": has_actual_errors
            },
            "context": context.to_dict()
        }
    
    def _print_test_summary(self, result: Dict[str, Any]):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        success = result.get("success", False)
        test_summary = result.get("test_summary", {})
        
        print(f"\nğŸ¯ é”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•æ‘˜è¦:")
        print(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        print(f"   ä¿®å¤å¾ªç¯æ¬¡æ•°: {test_summary.get('fix_attempts', 0)}")
        print(f"   æœ€å¤§å¾ªç¯æ¬¡æ•°: {test_summary.get('max_fix_attempts', 3)}")
        print(f"   å·¥ä½œæµå®Œæˆ: {test_summary.get('workflow_completed', False)}")
        print(f"   é”™è¯¯åˆ—è¡¨æ•°é‡: {test_summary.get('final_error_count', 0)}")
        print(f"     - é™æ€æ£€æŸ¥é”™è¯¯: {test_summary.get('static_errors', 0)}")
        print(f"     - ç¼–è¯‘é”™è¯¯: {test_summary.get('compile_errors', 0)}")
        print(f"   å®é™…æœ‰é”™è¯¯éœ€è¦ä¿®å¤: {test_summary.get('actual_errors', False)}")
        
        generated_files = result.get("generated_files", [])
        if generated_files:
            print(f"   ä¿®å¤çš„æ–‡ä»¶æ•°é‡: {len(generated_files)}")
            for file_info in generated_files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"     - {file_info.get('path', 'unknown')}: {file_info.get('status', 'unknown')}")
        
        # æ ¹æ®å®é™…é”™è¯¯çŠ¶æ€æ˜¾ç¤ºç»“æœ
        actual_errors = test_summary.get('actual_errors', False)
        if not actual_errors:
            print(f"\nğŸ‰ æ²¡æœ‰å®é™…é”™è¯¯ï¼Œæ£€æŸ¥é€šè¿‡ï¼")
        elif test_summary.get('fix_attempts', 0) >= test_summary.get('max_fix_attempts', 3):
            print(f"\nâš ï¸ è¾¾åˆ°æœ€å¤§ä¿®å¤æ¬¡æ•°ï¼Œä½†ä»æœ‰æœªè§£å†³çš„é”™è¯¯")
        
        print(f"\nğŸ“ è¯´æ˜:")
        print(f"   - æ­¤æµ‹è¯•ä¸“é—¨éªŒè¯é”™è¯¯ä¿®å¤å·¥ä½œæµäºŒçš„åŠŸèƒ½")
        print(f"   - ä»ç°æœ‰Index.etsæ–‡ä»¶å¼€å§‹è¿›è¡Œé”™è¯¯æ£€æŸ¥å’Œä¿®å¤")
        print(f"   - éªŒè¯é™æ€æ£€æŸ¥ã€ç¼–è¯‘æ£€æŸ¥å’Œå¾ªç¯ä¿®å¤æœºåˆ¶")
        print(f"   - åŒºåˆ†é”™è¯¯åˆ—è¡¨æ•°é‡å’Œå®é™…éœ€è¦ä¿®å¤çš„é”™è¯¯")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é”™è¯¯ä¿®å¤å·¥ä½œæµäºŒä¸“ç”¨æµ‹è¯•å·¥å…·")
    parser.add_argument("--config", type=str, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--requirement", type=str, 
                       default="æµ‹è¯•ç™»å½•é¡µé¢ç»„ä»¶çš„é”™è¯¯ä¿®å¤", 
                       help="æ¨¡æ‹Ÿç”¨æˆ·éœ€æ±‚ï¼ˆç”¨äºæœç´¢å…³é”®è¯ç”Ÿæˆï¼‰")
    parser.add_argument("--session-id", type=str, help="ä¼šè¯ID")
    parser.add_argument("--output", choices=["text", "json"], default="text",
                       help="è¾“å‡ºæ ¼å¼")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ErrorFixWorkflowTester()
    
    if not await tester.initialize(args.config):
        sys.exit(1)
    
    # æ‰§è¡Œé”™è¯¯ä¿®å¤å·¥ä½œæµæµ‹è¯•
    start_time = time.time()
    result = await tester.test_error_fix_workflow(
        user_requirement=args.requirement,
        session_id=args.session_id
    )
    end_time = time.time()
    
    # è¾“å‡ºç»“æœ
    if args.output == "json":
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print(f"\nâ±ï¸ æ€»æµ‹è¯•æ—¶é—´: {end_time - start_time:.2f}ç§’")
        
        if not result["success"]:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            if "suggestion" in result:
                print(f"ğŸ’¡ å»ºè®®: {result['suggestion']}")


if __name__ == "__main__":
    asyncio.run(main())